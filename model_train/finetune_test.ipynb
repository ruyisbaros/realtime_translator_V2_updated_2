{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 82010 files for de\n",
      "Processed 47831 files for tr\n",
      "Processed 65816 files for en\n",
      "✅ All files in lookup.json exist in the dataset!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Load the lookup.json file\n",
    "json_path = \"lookup.json\"  # Update path if needed\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lookup = json.load(f)\n",
    "\n",
    "missing_files = []\n",
    "\n",
    "# Loop through each language and check file existence\n",
    "for lang, wav_dict in lookup.items():\n",
    "    paths=0\n",
    "    for wav_filename, metadata in wav_dict.items():\n",
    "        speaker = metadata[\"speaker\"]\n",
    "        expected_path = f\"dataset/{lang}/{speaker}/{wav_filename}\"\n",
    "        \n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(expected_path):\n",
    "            missing_files.append(expected_path)\n",
    "        paths+=1\n",
    "    print(f\"Processed {paths} files for {lang}\")\n",
    "# Display the results\n",
    "if missing_files:\n",
    "    print(f\"❌ {len(missing_files)} missing files detected!\")\n",
    "    for file in missing_files[:10]:  # Show only first 10 for brevity\n",
    "        print(f\"   - {file}\")\n",
    "else:\n",
    "    print(\"✅ All files in lookup.json exist in the dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de': 7826, 'en': 6652, 'tr': 5086}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Load the lookup.json file\n",
    "lookup_path = \"lookup.json\"  # Adjust this path as needed\n",
    "output_path = \"lookup_10.json\"  # Output path for the selected subset\n",
    "\n",
    "# Define the target 10% distribution\n",
    "TARGET_PERCENTAGE = 0.10  # Select 10% of the dataset\n",
    "LANGUAGE_DISTRIBUTION = {\"de\": 0.40, \"en\": 0.34, \"tr\": 0.26}  # Adjust based on full dataset ratio\n",
    "\n",
    "# Load lookup.json\n",
    "with open(lookup_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lookup = json.load(f)\n",
    "\n",
    "# Count total number of audio files per language\n",
    "language_counts = {lang: len(files) for lang, files in lookup.items()}\n",
    "total_files = sum(language_counts.values())\n",
    "\n",
    "# Calculate the number of samples to select per language\n",
    "target_samples = int(total_files * TARGET_PERCENTAGE)\n",
    "selected_samples_per_lang = {\n",
    "    lang: int(target_samples * ratio) for lang, ratio in LANGUAGE_DISTRIBUTION.items()\n",
    "}\n",
    "\n",
    "# Ensure we don’t select more than available files\n",
    "for lang in selected_samples_per_lang:\n",
    "    selected_samples_per_lang[lang] = min(selected_samples_per_lang[lang], language_counts[lang])\n",
    "\n",
    "# Randomly select the required number of files per language\n",
    "selected_lookup = {}\n",
    "for lang, num_samples in selected_samples_per_lang.items():\n",
    "    selected_files = random.sample(list(lookup[lang].keys()), num_samples)\n",
    "    selected_lookup[lang] = {file: lookup[lang][file] for file in selected_files}\n",
    "\n",
    "# Save the selected subset to lookup_10.json\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(selected_lookup, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Display result summary\n",
    "selected_counts = {lang: len(files) for lang, files in selected_lookup.items()}\n",
    "selected_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3545-oval-bazaar-expand-9\n",
    "Zipping dataset to dataset.zip\n",
    "Adding dataset/tr/tolga/common_voice_tr_30807057.wav\n",
    "Sending 'dataset.zip' (59.8 GB)  \n",
    "Code is: 3545-oval-bazaar-expand-9\n",
    "On the other computer run\n",
    "\n",
    "runpodctl receive 3545-oval-bazaar-expand-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> train.txt metadata file created at: metadata_text_files_10percent/train.txt with 16630 entries.\n",
      " --> val.txt metadata file created at: metadata_text_files_10percent/val.txt with 2934 entries.\n",
      " --> JSON to text metadata conversion complete.\n",
      " --> train.txt metadata file created at: metadata_text_files_full/train.txt with 166309 entries.\n",
      " --> val.txt metadata file created at: metadata_text_files_full/val.txt with 29348 entries.\n",
      " --> JSON to text metadata conversion complete.\n",
      " --> Metadata conversion for both 10% and full datasets completed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "def convert_json_to_text_metadata(json_filepath, output_dir, validation_split=0.15):\n",
    "    \"\"\"\n",
    "    Converts a JSON dataset file to train.txt and val.txt metadata files\n",
    "    in the format 'audio_filepath|transcription' for Coqui-TTS.\n",
    "\n",
    "    Args:\n",
    "        json_filepath (str): Path to your input JSON dataset file.\n",
    "        output_dir (str): Directory to save train.txt and val.txt.\n",
    "        validation_split (float): Fraction of data to use for validation (e.g., 0.15 for 15%).\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    train_metadata_file = os.path.join(output_dir, \"train.txt\")\n",
    "    val_metadata_file = os.path.join(output_dir, \"val.txt\")\n",
    "\n",
    "    data_entries = []\n",
    "\n",
    "    with open(json_filepath, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    for lang_key, lang_data in json_data.items(): # Iterate through languages (e.g., \"de\", \"en\", \"tr\")\n",
    "        for wav_filename, wav_info in lang_data.items(): # Iterate through wav files in each language\n",
    "            transcription = wav_info[\"text\"]\n",
    "            speaker = wav_info[\"speaker\"] # You have speaker info in JSON, though we might not use it directly in basic fine-tuning\n",
    "\n",
    "            # Construct the full audio filepath based on your folder structure\n",
    "            # Assuming structure: dataset/lang/speaker/wav_files\n",
    "            audio_filepath = os.path.join(\"dataset\", lang_key, speaker, wav_filename) # **Adjust \"dataset\" if your root dataset folder is named differently**\n",
    "\n",
    "            data_entries.append({\"filepath\": audio_filepath, \"text\": transcription})\n",
    "\n",
    "    # Shuffle data entries for random train/val split\n",
    "    random.shuffle(data_entries)\n",
    "\n",
    "    val_size = int(len(data_entries) * validation_split)\n",
    "    val_entries = data_entries[:val_size]\n",
    "    train_entries = data_entries[val_size:]\n",
    "\n",
    "    # Write train.txt\n",
    "    with open(train_metadata_file, 'w', encoding='utf-8') as train_file:\n",
    "        for entry in train_entries:\n",
    "            train_file.write(f\"{entry['filepath']}|{entry['text']}\\n\")\n",
    "    print(f\" --> train.txt metadata file created at: {train_metadata_file} with {len(train_entries)} entries.\")\n",
    "\n",
    "    # Write val.txt\n",
    "    with open(val_metadata_file, 'w', encoding='utf-8') as val_file:\n",
    "        for entry in val_entries:\n",
    "            val_file.write(f\"{entry['filepath']}|{entry['text']}\\n\")\n",
    "    print(f\" --> val.txt metadata file created at: {val_metadata_file} with {len(val_entries)} entries.\")\n",
    "\n",
    "    print(\" --> JSON to text metadata conversion complete.\")\n",
    "\n",
    "\n",
    "# --- Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = \"lookup_10.json\" # **Replace with the path to your lookup_10.json file on Runpod**\n",
    "    output_directory = \"metadata_text_files_10percent\" # Directory to save train.txt and val.txt\n",
    "    convert_json_to_text_metadata(input_json_path, output_directory)\n",
    "\n",
    "    input_json_path_full = \"lookup.json\" # **Replace with the path to your full lookup.json file on Runpod**\n",
    "    output_directory_full = \"metadata_text_files_full\" # Directory to save train.txt and val.txt for full dataset\n",
    "    convert_json_to_text_metadata(input_json_path_full, output_directory_full)\n",
    "\n",
    "    print(\" --> Metadata conversion for both 10% and full datasets completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.config.shared_configs import BaseDatasetConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define here the dataset that you want to use for the fine-tuning on.\n",
    "config_dataset = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\",\n",
    "    dataset_name=\"ljspeech\",\n",
    "    path=\"/raid/datasets/LJSpeech-1.1_24khz/\",\n",
    "    meta_file_train=\"/raid/datasets/LJSpeech-1.1_24khz/metadata.csv\",\n",
    "    language=\"en\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
