{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wollen wir das Ganze einfach mal ausfÃ¼hren â†’ Ëˆwo.lle.n Ëˆwi.Ê Ëˆda.s Ëˆga.ntse Ëˆa.Éª.Ì¯nfa.x Ëˆma.l Ëˆa.ÊŠÌ¯sfÊ.hÊe.n\n",
      "Das ist ein Test â†’ Ëˆda.s Ëˆi.Êƒt Ëˆa.Éª.Ì¯n Ëˆte.Êƒt\n",
      "KÃ¶nnen wir den Text ins IPA umwandeln â†’ ËˆkÅ“.nne.n Ëˆwi.Ê Ëˆde.n Ëˆte.xt Ëˆi.ns Ëˆi.pa Ëˆu.mwa.nde.ln\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def german_to_ipa(text):\n",
    "    ipa_mapping = {\n",
    "        \"sch\": \"Êƒ\", \"ch\": \"x\", \"z\": \"ts\", \"j\": \"j\", \"r\": \"Ê\", \"ng\": \"Å‹\",\n",
    "        \"au\": \"aÊŠÌ¯\", \"ei\": \"aÉªÌ¯\", \"eu\": \"É”ÊÌ¯\", \"Ã¤u\": \"É”ÊÌ¯\", \"sp\": \"Êƒp\", \"st\": \"Êƒt\",\n",
    "        \"Ã¤\": \"É›\", \"Ã¶\": \"Å“\", \"Ã¼\": \"Ê\", \"ÃŸ\": \"s\", \"ph\": \"f\", \"qu\": \"kv\"\n",
    "    }\n",
    "\n",
    "    words = text.lower().split()\n",
    "    ipa_words = []\n",
    "\n",
    "    for word in words:\n",
    "        ipa_word = word\n",
    "        for key, val in ipa_mapping.items():\n",
    "            ipa_word = ipa_word.replace(key, val)\n",
    "\n",
    "        # Insert syllable boundaries and primary stress for the first syllable\n",
    "        ipa_word = re.sub(r\"([aeiouÃ¤Ã¶Ã¼ÉªÉ›Å“Ê])\", r\"\\1.\", ipa_word)  # syllables after vowels\n",
    "        ipa_word = re.sub(r\"\\.$\", \"\", ipa_word)  # remove trailing syllable\n",
    "        ipa_word = \"Ëˆ\" + ipa_word  # add primary stress\n",
    "\n",
    "        ipa_words.append(ipa_word)\n",
    "\n",
    "    return \" \".join(ipa_words)\n",
    "\n",
    "# Test the function\n",
    "sentences = [\n",
    "    \"Wollen wir das Ganze einfach mal ausfÃ¼hren\",\n",
    "    \"Das ist ein Test\",\n",
    "    \"KÃ¶nnen wir den Text ins IPA umwandeln\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    ipa = german_to_ipa(sentence.lower())\n",
    "    print(f\"{sentence} â†’ {ipa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… IPA conversion completed. Saved to audio_dataset_2/metadata_ipa.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def convert_metadata_to_ipa(input_file='audio_dataset_2/metadata.csv', output_file='audio_dataset_2/metadata_ipa.csv'):\n",
    "    \"\"\"Converts the second column of metadata.csv to IPA and saves it\"\"\"\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        reader = csv.reader(infile, delimiter='|')\n",
    "        writer = csv.writer(outfile, delimiter='|')\n",
    "\n",
    "        for row in reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "\n",
    "            original_text = row[1]\n",
    "            ipa_text = german_to_ipa(original_text)\n",
    "\n",
    "            new_row = [row[0], f\"/{ipa_text}/\", row[2]]\n",
    "            writer.writerow(new_row)\n",
    "\n",
    "    print(f\"âœ… IPA conversion completed. Saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Run the conversion\n",
    "convert_metadata_to_ipa()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Segmenting audio into chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_766575/2904774351.py:11: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(input_audio, sr=22050)\n",
      "/home/ahmet/anaconda3/envs/tts_env/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: audio_dataset_2/wavs/segment_000.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_001.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_002.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_003.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_004.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_005.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_006.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_007.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_008.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_009.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_010.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_011.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_012.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_013.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_014.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_015.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_016.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_017.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_018.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_019.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_020.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_021.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_022.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_023.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_024.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_025.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_026.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_027.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_028.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_029.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_030.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_031.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_032.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_033.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_034.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_035.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_036.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_037.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_038.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_039.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_040.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_041.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_042.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_043.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_044.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_045.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_046.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_047.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_048.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_049.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_050.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_051.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_052.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_053.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_054.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_055.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_056.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_057.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_058.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_059.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_060.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_061.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_062.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_063.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_064.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_065.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_066.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_067.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_068.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_069.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_070.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_071.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_072.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_073.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_074.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_075.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_076.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_077.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_078.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_079.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_080.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_081.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_082.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_083.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_084.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_085.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_086.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_087.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_088.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_089.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_090.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_091.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_092.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_093.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_094.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_095.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_096.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_097.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_098.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_099.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_100.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_101.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_102.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_103.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_104.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_105.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_106.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_107.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_108.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_109.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_110.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_111.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_112.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_113.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_114.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_115.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_116.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_117.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_118.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_119.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_120.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_121.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_122.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_123.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_124.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_125.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_126.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_127.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_128.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_129.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_130.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_131.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_132.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_133.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_134.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_135.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_136.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_137.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_138.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_139.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_140.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_141.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_142.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_143.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_144.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_145.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_146.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_147.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_148.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_149.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_150.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_151.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_152.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_153.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_154.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_155.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_156.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_157.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_158.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_159.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_160.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_161.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_162.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_163.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_164.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_165.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_166.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_167.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_168.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_169.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_170.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_171.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_172.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_173.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_174.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_175.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_176.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_177.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_178.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_179.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_180.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_181.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_182.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_183.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_184.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_185.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_186.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_187.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_188.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_189.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_190.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_191.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_192.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_193.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_194.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_195.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_196.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_197.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_198.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_199.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_200.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_201.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_202.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_203.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_204.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_205.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_206.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_207.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_208.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_209.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_210.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_211.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_212.wav (15s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_213.wav (5s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_214.wav (10s)\n",
      "âœ… Saved: audio_dataset_2/wavs/segment_215.wav (15s)\n",
      "ğŸ¯ Audio segmentation completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "input_audio = \"org.mp4\"\n",
    "output_dir = \"audio_dataset_2/wavs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def segment_audio(input_audio, output_dir, segment_durations=[5, 10, 15]):\n",
    "    print(\"ğŸ¯ Segmenting audio into chunks...\")\n",
    "    y, sr = librosa.load(input_audio, sr=22050)\n",
    "    total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "    current_position = 0\n",
    "    segment_count = 0\n",
    "\n",
    "    while current_position < total_duration:\n",
    "        duration = segment_durations[segment_count % len(segment_durations)]\n",
    "        end_position = min(current_position + duration, total_duration)\n",
    "\n",
    "        # Extract chunk\n",
    "        chunk = y[int(current_position * sr):int(end_position * sr)]\n",
    "        file_path = os.path.join(output_dir, f\"segment_{segment_count:03d}.wav\")\n",
    "\n",
    "        # Save chunk\n",
    "        sf.write(file_path, chunk, sr)\n",
    "        print(f\"âœ… Saved: {file_path} ({duration}s)\")\n",
    "        current_position = end_position\n",
    "        segment_count += 1\n",
    "\n",
    "    print(\"ğŸ¯ Audio segmentation completed!\")\n",
    "\n",
    "segment_audio(input_audio, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmet/anaconda3/envs/tts_env/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 7.75 GiB of which 24.44 MiB is free. Including non-PyTorch memory, this process has 7.17 GiB memory in use. Of the allocated memory 7.03 GiB is allocated by PyTorch, and 19.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedium\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/ahmet/.cache/whisper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m input_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_dataset_2/wavs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m metadata_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_dataset_2/metadata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/whisper/__init__.py:160\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alignment_heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_alignment_heads(alignment_heads)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 7.75 GiB of which 24.44 MiB is free. Including non-PyTorch memory, this process has 7.17 GiB memory in use. Of the allocated memory 7.03 GiB is allocated by PyTorch, and 19.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"medium\", download_root=\"/home/ahmet/.cache/whisper\")\n",
    "input_dir = \"audio_dataset_2/wavs\"\n",
    "metadata_path = \"audio_dataset_2/metadata.csv\"\n",
    "\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f_meta:\n",
    "    for file in sorted(os.listdir(input_dir)):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(input_dir, file)\n",
    "            print(f\"ğŸ™ï¸ Transcribing {file}...\")\n",
    "\n",
    "            try:\n",
    "                result = model.transcribe(file_path)\n",
    "                text = result['text'].strip()\n",
    "                f_meta.write(f\"{file}|{text}|{text}\\n\")\n",
    "                print(f\"âœ… {file}: {text[:50]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Failed to transcribe {file}: {e}\")\n",
    "\n",
    "print(\"ğŸ¯ Transcription completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmet/anaconda3/envs/tts_env/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ segment_0001.wav: Hallo und herzlich willkommen zur zweiten Folge von EinfÃ¼hrung in React mit dem Thema React Setup. Noch einmal kurz zu mir, mein Name ist David Losert, ich bin Software Engineer und seit Ã¼ber zehn Jahren im Web unterwegs und arbeite nun auch bereits seit vier Jahren.\n",
      "ğŸ“ segment_0002.wav: Jahren mit React. Neben React mache ich die Arbeit mit JavaScript, TypeScript, Node.js, Linux-Servern, Docker und AWS. Die heutige Folge dreht sich also nun komplett darum, eine Entwicklungs-\n",
      "ğŸ“ segment_0003.wav: Umgebung aufzusetzen und dort eine erste Reaction.\n",
      "ğŸ“ segment_0004.wav: Hello World Applikation zu implementieren. Wenn wir uns kurz erinnern, in der letzten Folge habe ich die Geschichte und Prinzipien von React kurz vorgestellt und einen ersten theoretischen Einblick auf die Geschichte und Prinzipien von React.\n",
      "ğŸ“ segment_0005.wav: Blick in den Virtual Dom und in JSX gegeben. Das habe ich an dieser Stelle auch einmal kurz visualisiert. Wir erinnern uns der Virtual Dom.\n",
      "ğŸ“ segment_0006.wav: ist eine Abstraktion, die React verwendet, um den DOM zu synchronisieren. Und der Virtual DOM erlaubt uns zum einen das Deklarative programmieren.\n",
      "ğŸ“ segment_0007.wav: und zum anderen gibt es uns einige Performance-Vorteile. In dieser Folge wollen wir nun eben also eine Entwicklungsumgebung auf der\n",
      "ğŸ“ segment_0008.wav: Ich nutze dazu Visual Studio Code. Wir werden uns ...\n",
      "ğŸ“ segment_0009.wav: ein erstes Toolset anschauen mit NPM, NPX und Babel.\n",
      "ğŸ“ segment_0010.wav: was uns bei der Entwicklung von React-Applikationen hilft. Und wir werden natÃ¼rlich...\n",
      "ğŸ“ segment_0011.wav: eine erste Reakt-Applikation implementieren und nutzen dazu das Reakt Element, ein atomarer Building Block von Reakt und JSX. In dieser Stelle werdet ihr vielleicht kurz aufmerken, ich habe das letzte mal viele von Reakt...\n",
      "ğŸ“ segment_0012.wav: Reakt-Components gesprochen. Reakt-Components sind nicht zu verwechseln mit Reakt-Element. Ich stelle nun aber in dieser Folge zuerst Reakt-Element vor, weil es sozusagen\n",
      "ğŸ“ segment_0013.wav: die Grundlage ist oder der atomare Baustein, der tatsÃ¤chlich atomare Baustein von React. Und React Element nimmt uns aus JSX auch so ein wenig die Magie. Denn wenn man JSX das erste Ball sieht, kann man sich schnell fragen...\n",
      "ğŸ“ segment_0014.wav: wie funktioniert das eigentlich hinter den Kulissen? Und React Element ist letztendlich das, was hinter den Kulissen steckt.\n",
      "ğŸ“ segment_0015.wav: am Ende der Folge dann auch einfach sehen. Bevor wir loslegen, mÃ¶chte ich euch ermutigen, alle Code-Beispiele und praktischen Hands-on-Teile, die wir in dieser Folge machen, nachzuprogrammieren. Der praktische Einsatz\n",
      "ğŸ“ segment_0016.wav: ist einfach der beste, um eine neue Technologie zu lernen.\n",
      "ğŸ“ segment_0017.wav: entweder machen, indem ihr nebenher programmiert und die Folge immer wieder pausiert oder aber\n",
      "ğŸ“ segment_0018.wav: durch die Folge einmal komplett an und programmiert das Beispiel im Nachhinein alleine. Wir werden den gesamten Code auch auf GitHub zur VerfÃ¼gung stellen. Das kann dann ein wenig als Orientierung dienen. Dabei geht einfach auf GitHub.\n",
      "ğŸ“ segment_0019.wav: und sucht dort nach tech-lounge-surject und ihr solltet das entsprechende Repository finden. Das ist aktuell hier noch leer, weil ich den Code natÃ¼rlich erst nach dieser Folge hochladen werde.\n",
      "ğŸ“ segment_0020.wav: wÃ¼rde ich sagen legen wir auch einfach schon mal los. Um unsere Umgebung vorzubereiten, mÃ¼ssen ein paar Schritte unternommen werden.\n",
      "ğŸ“ segment_0021.wav: Die haben jetzt mit React erstmal noch nichts zu tun. Zum einen mÃ¼sst ihr euch Visual Studio Code installieren. Oder mÃ¼sst ihr nicht, wenn ihr einen anderen Editor bevorzugt.\n",
      "ğŸ“ segment_0022.wav: ist das auch vollkommen okay. Ich arbeite nur hier mit Visual Studio Code, weil ich diese Idee doch recht gerne habe. Sie bittet mir einige UnterstÃ¼tzung, zum Beispiel CodevervollstÃ¤ndigung, was wir nachher auch sehen werden.\n",
      "ğŸ“ segment_0023.wav: einer Entwicklungsumgebung Visual Studio Code brauchen wir Node.js und NPM.\n",
      "ğŸ“ segment_0024.wav: Da erklÃ¤re ich auch gleich ein paar Worte zu. Und wir mÃ¼ssen natÃ¼rlich ein...\n",
      "ğŸ“ segment_0025.wav: Projektordner anlegen und unsere Umgebung vorbereiten mit ein paar wenigen Commands in der Kommandozeile. Ein paar Worte zu NPM, falls ihr das noch nicht gehÃ¶rt habt. NPM ist ein Paketmanager.\n",
      "ğŸ“ segment_0026.wav: fÃ¼r JavaScript Tools, Bibliotheken und Frameworks und erlaubt uns Ã¼ber ein\n",
      "ğŸ“ segment_0027.wav: eine einfache Command Line Interface, das installieren und verwalten eben dieser Tool.\n",
      "ğŸ“ segment_0028.wav: Bibliotheken und Frameworks. Das ist ein einfacher Befehl wie npm install.\n",
      "ğŸ“ segment_0029.wav: der uns AbhÃ¤ngigkeiten unserer Projekt installiert. Bei NPM dreht sich eigentlich alles um die Package Chasing.\n",
      "ğŸ“ segment_0030.wav: eine Datei, die wir in unserem Projektordner im Bootfolder machen.\n",
      "ğŸ“ segment_0031.wav: erstellen werden und in dieser Package JSON sind AbhÃ¤ngigkeiten beschrieben, Skripte und auch ...\n",
      "ğŸ“ segment_0032.wav: Projekt Metadaten.\n",
      "ğŸ“ segment_0033.wav: das NPM mitbringt ist NPX.\n",
      "ğŸ“ segment_0034.wav: Und das ermÃ¶glicht uns die AusfÃ¼hrung all dieser JavaScript Tools Bibliotheken und Frameworks ohne eine Installation.\n",
      "ğŸ“ segment_0035.wav: Das kÃ¶nnen wir zum Beispiel nutzen, um einen lokalen Webserver zu starten, der unser Testprojekt ausliefert.\n",
      "ğŸ“ segment_0036.wav: und das werden wir auch tun. Und wir werden dazu den Webserver Servor verwenden. Das ist kein Schreibfehler. Dieses Paket heiÃŸt wirklich so. NPX Servor startet mit diesem Befehl einen lokalen\n",
      "ğŸ“ segment_0037.wav: Web Server im aktuellen Verzeichnis. Wir haben hier noch das Argument minus minus reload. Das erlaubt uns oder das erlaubt\n",
      "ğŸ“ segment_0038.wav: dem Server alle Dateien, die in unserem Projekt sich tummeln, zu beobachten und bei einer Ã„nderung unseren Browser automatisch neu zu laden. Das ist wÃ¤hrend der Entwicklung sehr bequem.\n",
      "ğŸ“ segment_0039.wav: weil es uns das Neuladen der Seite hÃ¤ndisch erspart, indem wir entweder F5 drÃ¼cken oder hier Ã¼ber den Reload-Button die Seite neu laden. Wenn wir diesen Befehl per Default ausfÃ¼hren, liefert er eine Index-Handung.\n",
      "ğŸ“ segment_0040.wav: HTML, welche wir auch gleich erstellen werden, im aktuellen Ordner unter der Adresse htdp localhost 8080 aus. Und nun um euch auch mal zu zeigen, wie ein MPM-Paket auf der Registry ausschaut.\n",
      "ğŸ“ segment_0041.wav: hier unter npm.js.com habt ihr eine Suche, in der ihr alle...\n",
      "ğŸ“ segment_0042.wav: Pakete, die es so gibt, suchen kÃ¶nnt. Und fÃ¼r jedes Paket gibt es dann auch eine Seite mit einer Beschreibung und Installationsanweisungen.\n",
      "ğŸ“ segment_0043.wav: was man halt zu diesem Paket wissen muss. Wollen wir das Ganze einfach mal ausfÃ¼hren? Dazu gehen wir also in unserer Command Line und legen uns...\n",
      "ğŸ“ segment_0044.wav: erstmal einen Ordner an. Den nenne ich hier einfach mal EinfÃ¼hrung Reakt. Jetzt sieht man, dass ich den zuvor schon angelegt habe.\n",
      "ğŸ“ segment_0045.wav: Deswegen bringt er mir hier einen Error. Bei euch wird das dann funktionieren. Wir kÃ¶nnen einfach in diesem Ordner reinnamigieren und wir werden den Befehl npm init ausfÃ¼llen. npm init erzeugt uns eben eine Package JSON, eine Initialen und spart uns so ein wenig.\n",
      "ğŸ“ segment_0046.wav: das von Hand zu tun, indem es uns Ã¼ber die Kommandozeile ein paar Fragen...\n",
      "ğŸ“ segment_0047.wav: stellt. Als allererstes will es den Package-Name von uns wissen, den es per Default-Package\n",
      "ğŸ“ segment_0048.wav: aus dem aktuellen Ordner einfach herauszieht. Einfach umreakt ist in diesem Fall ok. Die Version ist fÃ¼r uns jetzt auch erstmal ok. Wir erinnern uns kurz an die letzte Folge.\n",
      "ğŸ“ segment_0049.wav: Semper, Semantik Verschmung, kommt bei NPM ganz stark zum Einsatz. Eine Description, da kÃ¶nnen wir uns einfach irgendeinen Freitext Ã¼berlegen. Das ist eine EinfÃ¼hrung in React zum Beispiel.\n",
      "ğŸ“ segment_0050.wav: Der Entry Point werden wir nachher sehen.\n",
      "ğŸ“ segment_0051.wav: Testcommand wir haben keine\n",
      "ğŸ“ segment_0052.wav: automatisierten Test, deswegen lassen wir das leer. Wir haben auch noch kein Git Repository eingerichtet.\n",
      "ğŸ“ segment_0053.wav: erstmal keine Keywords vergeben. Den Author kÃ¶nnen wir uns selber reinschreiben.\n",
      "ğŸ“ segment_0054.wav: und eine Lizenz ist bei privaten Testprojekten auch eher nicht ganz so wichtig. Ich nehme hier in der Regel immer MIT.\n",
      "ğŸ“ segment_0055.wav: aber im Prinzip auch auf ISC lassen. NPM fragt uns das nochmal, ob alle unsere Eingaben korrekt waren und wird uns eben diese Chasing-Datei\n",
      "ğŸ“ segment_0056.wav: als Package JSON im aktuellen Verzeichnis anlegen. In unserem Fall ist das jetzt ok, deswegen yes. Als nÃ¤chstes Ã¶ffnen wir nun diesen Ordner in unserer Entwicklungsumgebung. In meinem Fall ist das eben Bishul Studio Code.\n",
      "ğŸ“ segment_0057.wav: Das kÃ¶nnen wir ganz einfach machen, indem wir hier auf File Open gehen.\n",
      "ğŸ“ segment_0058.wav: zum entsprechenden Ort navigieren und dann auf Ã¶ffnen drÃ¼cken. Und jetzt sehen wir, dass uns eben eine Package-Json generiert wurde, in der all die Felder, die wir vorher befragen haben,\n",
      "ğŸ“ segment_0059.wav: beantwortet haben, entsprechend eingetragen sind. Als nÃ¤chsten Schritt wollen wir uns nun also eine noch eine Index HTML anlegen, also eine initiale HTML-Seite, die ausgeliefert werden kann.\n",
      "ğŸ“ segment_0060.wav: Das machen wir Ã¼ber den New File, index.html. Und dort schreiben wir einfach eine standardmÃ¤ÃŸige HTML-Datei, angefangen mit dem Doctype.\n",
      "ğŸ“ segment_0061.wav: Und hier haben wir jetzt schon ein tolles Feature von Visual Studio Code gesehen, die AutovervollstÃ¤ndigung. Ich lÃ¶sche das nochmal.\n",
      "ğŸ“ segment_0062.wav: das Codes eingebe, den ich hier erzeugen will, bietet mir Visual Studio Code schon eine Vorauswahl an. Wenn ich diese bestÃ¤tige entweder Ã¼ber Enter oder indem ich trau...\n",
      "ğŸ“ segment_0063.wav: klickte, fÃ¼llt es mir das entsprechend aus. Im klassischen HTML-Dokument kommt das nÃ¤chste HTML. Wir brauchen einen Het oder einen Het-Tag, in welchem wir dann einen Titel vergeben.\n",
      "ğŸ“ segment_0064.wav: kÃ¶nnen. Das nennen wir mal EinfÃ¼hrung in Reakt. Und wir brauchen ein Buddy und da wollen wir jetzt einfach wieder suchen.\n",
      "ğŸ“ segment_0065.wav: Ã¼blich ist bei einem Code Beispiel mit Hello World anfangen. Wenn ich nur noch Speichern drÃ¼cke, nicht wundern, das ist auch ein Feature von Visual Studio Code.\n",
      "ğŸ“ segment_0066.wav: Das ist mir automatisch mein Dokument.\n",
      "ğŸ“ segment_0067.wav: nach gewissen Kriterien formatiert. Dementsprechend kann es sein, dass sie manchmal ein Zeichen...\n",
      "ğŸ“ segment_0068.wav: Umbruch hinzugefÃ¼gt wird. Das ist einfach sehr bequem, das ist immer alles.\n",
      "ğŸ“ segment_0069.wav: einheitlich formatiert wird. So, nun haben wir eine Index-HTML erstellt. Diese wollen wir jetzt natÃ¼rlich noch Ã¼ber einen Web-Server ausliefern, um unsere Entwicklungsumgebung zu vervollstÃ¤ndigen. Und wie vorher besprochen, nehmen wir dazu NPE.\n",
      "ğŸ“ segment_0070.wav: ein npx servo minus minus reload das dauert kurz und gibt uns dann hier auch entsprechend zurÃ¼ck dass nun unter htp localhost\n",
      "ğŸ“ segment_0071.wav: 8080 die aktuelle Website oder der aktuelle Ordner ausgeliefert wird und standardmÃ¤ÃŸig eben diese Index HTML ausgeliefert wird und das sehen wir auch in dem wir zum Browser\n",
      "ğŸ“ segment_0072.wav: navigieren und entsprechend diese URL eingeben.\n",
      "ğŸ“ segment_0073.wav: Und hier da unsere Hello World Index HTML wird ausgeliefert. Eine kleine UnschÃ¶nheit sehen wir hier noch. EinfÃ¼hrung in React. Das Ãœ hat er irgendwie noch nicht erkannt. Dazu mÃ¼ssen wir in dem HTML im Het-Teil...\n",
      "ğŸ“ segment_0074.wav: noch das Charset auf UTF-8 setzen. Das geht auch ganz einfach, indem wir ja ein Neta-Charset Felt-UTF-8 eingeben. Wir drÃ¼cken Speichern und wenn wir nun zur BrÃ¼cke\n",
      "ğŸ“ segment_0075.wav: auf die Website navigieren, sehen wir, dass das Reload Flag von Server schon seinen Job getan hat, die Seite wurde automatisch neu geladen und das Ãœ wird hier nun korrekt dargestellt. Und damit haben wir im Wesentlichen schon eine laute\n",
      "ğŸ“ segment_0076.wav: Entwicklungsungebung, in der wir nun React entwickeln kÃ¶nnen. Dazu nun wieder ein bisschen Theorie. Es gibt mehrere ...\n",
      "ğŸ“ segment_0077.wav: Methoden, wie wir React nun in unser Projekt installieren kÃ¶nnen oder wie wir auch React aufsetzen kÃ¶nnen. Die einfachste Methode sind Online Playgrounds. Online Playgrounds sind\n",
      "ğŸ“ segment_0078.wav: im Prinzip Entwicklungsumgebung direkt im Browser. React bietet selber auf seiner Seite Dokumentationen, einen Online-Breaker und an, zum Beispiel CodePen. Das kÃ¶nnen wir uns auch mal ganz kurz anschauen. Wir gehen auf Get Started, drÃ¼cken, Try React.\n",
      "ğŸ“ segment_0079.wav: sehen wir hier die Online-Breakdowns. Wenn wir da zum Beispiel auf CodePen navigieren,\n",
      "ğŸ“ segment_0080.wav: werden wir gleich weiter geladen.\n",
      "ğŸ“ segment_0081.wav: und haben nun hier ebenfalls eine Hello World Applikation von React, die wir entsprechend auch bearbeiten kÃ¶nnen.\n",
      "ğŸ“ segment_0082.wav: Command-Enter wird die Seite nun aktualisiert. Das ist wie gesagt super, um React auszuprobieren.\n",
      "ğŸ“ segment_0083.wav: bei euch lokal nicht funktioniert, nachzustellen. Aber wenn wir langfristig Projekte entwickeln, wollen wir natÃ¼rlich irgendwie den Code, den wir produzieren, auch richtig abspeichern.\n",
      "ğŸ“ segment_0084.wav: ist in diesen Online-Playgrounds eher schwierig mÃ¶glich. Dementsprechend wollen wir den Code irgendwie lokal bei uns zur VerfÃ¼gung haben. Eine zweite Minute wÃ¤re natÃ¼rlich, den Quellcode von React runterzuladen. KÃ¶nnten wir mal...\n",
      "ğŸ“ segment_0085.wav: ist heutzutage aber eher altmodisch.\n",
      "ğŸ“ segment_0086.wav: wenn wir zum Beispiel eine neue Version von React installieren wollen, mÃ¼ssten wir wieder auf die React-Webseite den Code herunterladen. Also das ist ein Vorgehen, welches eher heutzutage nicht mehr zu empfehlen ist. Da gibt es hÃ¶here Methoden. Die eine, die wir jetzt in der\n",
      "ğŸ“ segment_0087.wav: ist die Nutzung einer sogenannten CDN-URL. CDN steht fÃ¼r Content Delivery Network. Das ist letztendlich einfach eine Website, auf der React uns den Quellkurs macht.\n",
      "ğŸ“ segment_0088.wav: schon einmal hochgeladen hat und den wir Ã¼ber die URL ganz einfach in unserer Index-HTML einbinden kÃ¶nnen. Und das ist ideal fÃ¼r schnelle Tests oder auch fÃ¼r Lernprojekte, so wie dieses Jahr hier ein Lernprojekt ist. Und dementsprechend werden wir auch heute\n",
      "ğŸ“ segment_0089.wav: diese Variante der Installation von React zurÃ¼ckgreifen. Die vierte Variante, die es auch noch gibt, ist natÃ¼rlich\n",
      "ğŸ“ segment_0090.wav: die Installation mit NPM. Den React gibt es auch auf NPM. Das zeige ich euch an dieser Stelle.\n",
      "ğŸ“ segment_0091.wav: nicht. Rack wurde auch auf NPM hochgeladen. Es ist allerdings so, dass die Installation Ã¼ber NPM beziehungsweise danach die Einbindung in eure Website nicht ganz so leicht ist.\n",
      "ğŸ“ segment_0092.wav: von da angeht. Da braucht es dann doch das ein oder andere Tool, was die Sache initial sehr komplex macht. Das rentiert sich bei grÃ¶ÃŸeren Applikationen aber absolut, denn dieser initial komplexe Aufwand wird dann amortisiert.\n",
      "ğŸ“ segment_0093.wav: Ã¼ber viel Arbeit, die uns diese Variante spÃ¤ter erspart. Die Installation von Reakt mit NPM werden wir in einer spÃ¤teren Folge dann auch noch vornehmen, spÃ¤testens im zweiten Teil dieser Videoserie, wo sich ja alles um das Tooling drehen wird.\n",
      "ğŸ“ segment_0094.wav: FÃ¼r heute, wie gesagt, nutzen wir auch\n",
      "ğŸ“ segment_0095.wav: den CDL URL Link. Das Ganze sieht dann so aus.\n",
      "ğŸ“ segment_0096.wav: dass wir in unserer index.html diese zwei Script Tags einfÃ¼hren. Und damit ist...\n",
      "ğŸ“ segment_0097.wav: dann auf unserer Seite schon verfÃ¼gbar. Diese zwei Script Text findet ihr ebenfalls auf der react.js.org auf der offiziellen Seite unter CDN Links. Ihr werdet ihr sehen, das ist zwei unterschiedliche Varianten.\n",
      "ğŸ“ segment_0098.wav: die Projekt einzublenden, einmal im Development Modus und einmal im Production Modus. Der Unterschied ist ganz einfach, dass der Development Modus einige bessere Fehlermeldungen zur VerfÃ¼gung stellt und einige Tools uns zur VerfÃ¼gung stellt, die das entwickeln von\n",
      "ğŸ“ segment_0099.wav: React leichter machen, die aber gleichzeitig diese JavaScript-Dateien sehr aufplÃ¤nen und sehr groÃŸ machen. Im produktiven Einsatz von React wollen wir natÃ¼rlich so wenig wie mÃ¶glich Code auf der Seite, weil der ja auch heruntergeladen werden muss. Dementsprechend hier diese Unterscheidungen. Da wir jetzt aber noch\n",
      "ğŸ“ segment_0100.wav: weit weg sind von einem produktiven Einsatz, beschrÃ¤nken wir uns heute auf die Development Sources, die ich hier einfach schon mal kopiere. Wenn wir dann nachher die Reaktion von der Reaktion von der Reaktion von der Reaktion\n",
      "ğŸ“ segment_0101.wav: in unserem Projekt eingebunden haben, wollen wir...\n",
      "ğŸ“ segment_0102.wav: natÃ¼rlich auch verwenden. Und den ersten Code oder das erste Code, das wir jetzt in der ersten Runde haben, das ist der Code, der wir jetzt in der ersten Runde haben. Und das ist der Code, der wir jetzt in der ersten Runde haben. Und das ist der Code, der wir jetzt in der ersten Runde haben. Und das ist der Code, der wir jetzt in der ersten Runde haben. Und das ist der Code, der wir jetzt in der ersten Runde haben. Und das ist der Code,\n",
      "ğŸ“ segment_0103.wav: Der erste, den ersten Block mit React, den wir verwenden werden, ist eben, wie vorher angekÃ¼ndigt, schon React Element. React Element oder ein React Element erstellen wir Ã¼ber diesen Funktionsauffruch React CreateElement und der besteht aus drei Parametern.\n",
      "ğŸ“ segment_0104.wav: Der erste Parameter gibt das HTML-Tag an, das wir generieren wollen. In diesem Fall zum Beispiel ein P-Tag.\n",
      "ğŸ“ segment_0105.wav: Der zweite Parameter gibt an, welche Attribute wir diesem HTML-Tag mitgeben wollen. In diesem Fall jetzt eine IT. Und der dritte Parameter gibt an, welchen Inhalt wir in dieses HTML-Tag reinstellen.\n",
      "ğŸ“ segment_0106.wav: in dem Fall hier jetzt myContent. Dieser Funktionsaufruf macht letztendlich nichts anderes als ein simples JavaScript-Objekt zu erzeugen. Dieses JavaScript-Objekt wird aber von React verstanden und kann dann von React\n",
      "ğŸ“ segment_0107.wav: wiederum in den Virtual DOM von React implementiert werden oder eigentlich.\n",
      "ğŸ“ segment_0108.wav: werden. Sobald es im Virtual Dom eingebunden ist, wir erinnern uns, React synchronisiert den\n",
      "ğŸ“ segment_0109.wav: Virtual Dom, dann mit dem richtigen Dom, wird eben dieses Element zu einem realen Dom-Objekt und dementsprechend dem Browser dargestellt. Man kann also sagen, dass ein React-Element ein reales Dom ist.\n",
      "ğŸ“ segment_0110.wav: Objekt reprÃ¤sentiert.\n",
      "ğŸ“ segment_0111.wav: Visualisierung noch einmal anschauen. Haben wir nun also neben dem VirtualDOM fÃ¼r React in unseren JavaScript-Dateien diesen Funktionsaufruf ReactCreateElement, welcher dann eben hier im VirtualDOM als einzelnen Element eingebunden wird, dann mit dem DOM Synchron.\n",
      "ğŸ“ segment_0112.wav: und nachher in unserem Browser dargestellt. Dieser Visualisierung habe ich ebenfalls npm hinzugefÃ¼gt, welches eben Ã¼ber die Package Chasing, die wir gerade schon gesehen haben, initialisiert und installiert wird. Und wir haben npx kennengelernt.\n",
      "ğŸ“ segment_0113.wav: was uns den Wert selber startet.\n",
      "ğŸ“ segment_0114.wav: wollen wir das Ganze noch einmal eben umsetzen. Wir kopieren nochmal kurz die Sources.\n",
      "ğŸ“ segment_0115.wav: Die brauchen wir jetzt als allererstes. Gehen zurÃ¼ck in unser V-Shirt.\n",
      "ğŸ“ segment_0116.wav: Studio und fÃ¼gen nun React ganz einfach am Ende des Bodytags ein. An sich war es das schon. Jetzt haben wir React auf unserer Seite.\n",
      "ğŸ“ segment_0117.wav: Wir tun aber natÃ¼rlich noch nichts damit. Um nur etwas damit zu tun, brauchen wir noch etwas eigenes JavaScript, das wir einbetten. Dementsprechend fÃ¼gen wir nun erstmal hier noch ein zweites oder ein drittes Script Tag hinzu. Das bei uns auch.\n",
      "ğŸ“ segment_0118.wav: auf sourceapp.js zeigen wird. Dieser Datei legen wir dann noch an. Erstmal ein Ordner source. Das ist einfach ein gÃ¤ngiges Vorgehen.\n",
      "ğŸ“ segment_0119.wav: eben fÃ¼r Source, in dem alle Source-Dateien eines Projektes abgelegt werden. Dort legen wir dann die Datei an. App.js. Bevor wir nun JavaScript schreiben, bereiten wir in der index.html\n",
      "ğŸ“ segment_0120.wav: noch eine weitere Sache vor. Wir erinnern uns vielleicht das letzte Mal an die React DOM Render\n",
      "ğŸ“ segment_0121.wav: Funktion, der wir zum einen mitgeben, eine React-Komponente, die wir gerendert haben wollen, zum anderen aber auch angeben mÃ¼ssen, wohin.\n",
      "ğŸ“ segment_0122.wav: in unserem HTML wir diese Komponente gewinnert haben wollen. Und dieses wohin erstellen wir jetzt hier. Wir machen uns ein einfaches div und geben dem eine ID anhand der wir es dann spÃ¤ter identifizieren kÃ¶nnen und das nennen wir...\n",
      "ğŸ“ segment_0123.wav: dann einfach react in das App.\n",
      "ğŸ“ segment_0124.wav: kurz auf die Seite schauen. Es hat sich nichts verÃ¤ndert. Alles beim alten, weil wir noch kein Reakt-Element generiert haben, das wir hier einbinden. Das tun wir jetzt. Zuerst generieren wir uns\n",
      "ğŸ“ segment_0125.wav: also ein React Element. Das speichern wir in eine Variable, die wir jetzt einfach mal Element nennen, nutzen und eben React.\n",
      "ğŸ“ segment_0126.wav: createElement. Reakt, design included.\n",
      "ğŸ“ segment_0127.wav: Variable, die uns jetzt eben zur VerfÃ¼gung steht, weil wir ja hier diese Ã¼ber dieses Script eingebunden haben. Das Script macht letztendlich nichts anderes als die Reakt-Sourcen unter dieser Variablen zur VerfÃ¼gung.\n",
      "ğŸ“ segment_0128.wav: zu stellen und so auch die CreateElement-Methode. Als ersten Parameter eben das Tag, in dem Fall bleiben wir mal beim Ptag. Als zweitem Parameter\n",
      "ğŸ“ segment_0129.wav: die Attribute. Das lassen wir erstmal leer. Und als dritten Parameter den Content. Wir schreiben jetzt einfach rein.\n",
      "ğŸ“ segment_0130.wav: Das ist mein erster Projekt.\n",
      "ğŸ“ segment_0131.wav: erstes React Element. Richtiger. Wie nur angesprochen, React Create Element generiert erst mal nur ein simples JavaScript-Objekt. Mit diesem Objekt mÃ¼ssen wir jetzt noch etwas tun.\n",
      "ğŸ“ segment_0132.wav: mÃ¼ssen wir sagen, wohin es uns dieses JavaScript objektiv\n",
      "ğŸ“ segment_0133.wav: oder dieses React Element nachher im Browser rendern soll.\n",
      "ğŸ“ segment_0134.wav: und dazu nutzen wir React-DOM. Das ist ebenfalls eine globale Variable, die uns zur VerfÃ¼gung steht, weil wir hier dieses zweite Skript eingebunden haben fÃ¼r React-DOM. Das liefert uns eben die Renderfunktion.\n",
      "ğŸ“ segment_0135.wav: und die wir noch zuerst unser Element reingeben. Und nun sagen mÃ¼ssen, wohin wir das gewendet haben wollen.\n",
      "ğŸ“ segment_0136.wav: uns ja vorher das div angelegt und eine id verpasst und das kÃ¶nnen wir hier\n",
      "ğŸ“ segment_0137.wav: nun mit einem Selektor herausfinden oder herausfiltern, indem wir sagen document getElementById und hier die ID, die wir\n",
      "ğŸ“ segment_0138.wav: vorher vergeben haben, in dem Fall React App. Kopieren und einfÃ¼gen. Wenn wir das Ganze speichern und auf die Website gehen, dann sehen wir, juhu, wir haben unsere\n",
      "ğŸ“ segment_0139.wav: erste Projekt-Element auf der\n",
      "ğŸ“ segment_0140.wav: Website gerendert. Wir haben zum allerersten Mal React eingesetzt um unseren\n",
      "ğŸ“ segment_0141.wav: Daumen zu manipulieren. Das ist natÃ¼rlich jetzt noch etwas statisch, aber ist doch Ã¼berall schon mal ein toller\n",
      "ğŸ“ segment_0142.wav: erster Schritt. Jetzt werdet ihr euch fragen, ich habe das letzte mal erzÃ¤hlt von deklarativen Programmieren und von JSX, dass es uns erlaubt HTML in JavaScript-Dateien zu schreiben. Ihr wÃ¼rdet nun erwarten, dass wir eigentlich...\n",
      "ğŸ“ segment_0143.wav: das ganze nicht hier mit dem Reactor Element Aufruf machen, sondern eher so\n",
      "ğŸ“ segment_0144.wav: schreiben kÃ¶nnen, wie so. Also ein HTML Element mit der IID direkt in der IID.\n",
      "ğŸ“ segment_0145.wav: JavaScript-Datei.\n",
      "ğŸ“ segment_0146.wav: werden wir einen Fehler bekommen. Wenn wir zurÃ¼ck navigieren in den Browser, sehen wir zum einen, dass unsere Elemente\n",
      "ğŸ“ segment_0147.wav: nicht mehr gerendert wurde. Um herauszufinden, was hier gerade schiefgelaufen ist, kÃ¶nnen wir die Entwicklertools von Chrome oder auch von jedem anderen Browser, jeder Browser bringt Entwicklertools mit, uns zur Hand nehmen. Das kÃ¶nnen wir entweder Ã¼ber die Taste F12 machen oder â€¦\n",
      "ğŸ“ segment_0148.wav: dem wir rechtsklick untersuchen machen.\n",
      "ğŸ“ segment_0149.wav: untersuchen sehen wir dann unseren aktuellen DOM oder unser HTML, das wir auch hier durchnavigieren kÃ¶nnen. Unser Title, unser MetaCharSet, eben der Buddy.\n",
      "ğŸ“ segment_0150.wav: und dann mal hinzuklicken. So, perfekt. Und wir haben auch die Konsole.\n",
      "ğŸ“ segment_0151.wav: die uns Fehler ausspuckt. Und in diesem Fall sehen wir jetzt\n",
      "ğŸ“ segment_0152.wav: Wir haben einen SÃ¼ndungsfehler. Ein unerwartetes Zeichen.\n",
      "ğŸ“ segment_0153.wav: Unexpected Token, eine geÃ¶ffnete Klammer. Und das ist genau dieses Zeichen. Blick daran, dass ein Browser heutzutage zumindest noch\n",
      "ğŸ“ segment_0154.wav: nicht JSX versteht. Ein Browser versteht nur natives JavaScript und das hier ist nun mal kein natives JavaScript. Dementsprechend kann der Browser\n",
      "ğŸ“ segment_0155.wav: diesen Coach-Schnippel einfach auch nicht verstehen. Und wir mÃ¼ssen erst etwas tun.\n",
      "ğŸ“ segment_0156.wav: damit er das kann. Wir mÃ¼ssen nÃ¤mlich diesen Code Snippet zurÃ¼ck umwandeln in ganz normales JavaScript. Und an dieser Stelle schon ein kleiner Hint. React-Create-Element ist ganz normales JavaScript. Das haben wir gerade gesehen, dass das funktioniert. Und das nutze ich jetzt.\n",
      "ğŸ“ segment_0157.wav: ermÃ¶glichen und um diese Ãœbersetzung vorzunehmen, das mÃ¼ssen wir natÃ¼rlich nicht hÃ¤ndisch machen, das wÃ¤re sehr aufwendig, sondern da gibt es Tools. Und eines dieser Tools...\n",
      "ğŸ“ segment_0158.wav: Wir gehen zurÃ¼ck zur Theorie, Test Babel.\n",
      "ğŸ“ segment_0159.wav: eben so eine Art Helferin oder eine Ãœbersetzerin, die uns Features und Funktionen, sowie GSX, zurÃ¼ck Ã¼bersetzt in natives JavaScript, das der Browser versteht. Babel besteht im Wesentlichen aus drei Kernkomponenten.\n",
      "ğŸ“ segment_0160.wav: die wir heute einsetzen werden. Das ist einmal der Core. Das ist die gesamte Ãœbersetzungslogik. Das Command-Win-Interface oder kurz CLI, das lÃ¤sst\n",
      "ğŸ“ segment_0161.wav: uns mit Babel kommunizieren und sprechen und Babel mitteilen, was wir eigentlich Ã¼bersetzt haben wollen. Und es gibt Presets. Presets kÃ¶nnt ihr euch vorstellen als WÃ¶rterbÃ¼cher, die wir Babel mitgeben, um Babel zu ermÃ¶glichen, beispielsweise JSX in Normal.\n",
      "ğŸ“ segment_0162.wav: JavaScript zu Ã¼bersetzen. Und wir setzen heute Preset React ein.\n",
      "ğŸ“ segment_0163.wav: React ist eben genau dieses WÃ¶rterbuch, das den Einsatz von JSX in unseren Dateien erlaubt. Und Babel wird dieses JSX dann umwandeln.\n",
      "ğŸ“ segment_0164.wav: ganz normales JavaScript.\n",
      "ğŸ“ segment_0165.wav: schauen. Aktuell standen wir hier mit JavaScript.\n",
      "ğŸ“ segment_0166.wav: von Create Element ausgefÃ¼hrt. Das hat funktioniert, haben jetzt aber JSX mit reingebracht.\n",
      "ğŸ“ segment_0167.wav: gebracht. Das hat nicht mehr funktioniert. JSX mÃ¼ssen wir also nun erst durch Babel schleifen.\n",
      "ğŸ“ segment_0168.wav: normales JavaScript umzuwandeln, das dann wiederum von React bzw. von unseren Browsern auch verstanden werden kann. Und an dieser Stelle wird es vielleicht schon langsam bewusst. Babel macht nichts anderes als aus diesen JSXs.\n",
      "ğŸ“ segment_0169.wav: Snippets oder aus den HTML-Teilen in JavaScript, die wir in JSX schreiben. react.create-elements.\n",
      "ğŸ“ segment_0170.wav: Funktionsaufrufe zu machen. Das ist die ganze Magie, die ...\n",
      "ğŸ“ segment_0171.wav: dahinter steckt und das zeige ich euch auch gleich hands-on. Aber zuerst, wie installieren wir Babel? Dazu nutzen wir nun eben NPM und wir werden den Babel Core\n",
      "ğŸ“ segment_0172.wav: die Babel CLI und das Preset React in unserem Projekt installieren.\n",
      "ğŸ“ segment_0173.wav: Und das machen wir jetzt.\n",
      "ğŸ“ segment_0174.wav: also in die Command Line. Wir beenden mal kurz unseren Web Server an dieser Stelle und fÃ¼hren nun das Command aus. npm install add fabel core add fabel cli\n",
      "ğŸ“ segment_0175.wav: und add-bobble-reset-react. Wir fÃ¼gen hier noch einen kleinen weiteren Parameter hinzu, nÃ¤mlich \"-save-def\". Warum wir das tun, erklÃ¤re ich dann gleich.\n",
      "ğŸ“ segment_0176.wav: estava\n",
      "ğŸ“ segment_0177.wav: weil er die ganzen Pakete natÃ¼rlich erst runterladen muss. Jetzt seht ihr hier ein Error, das passiert auf Mac. Nicht wundern, wenn ihr diesen Error seht und auch keine Sorge, das spielt fÃ¼r uns erstmal keine Rolle. Ein paar Features von Babel werden wegen diesem Error...\n",
      "ğŸ“ segment_0178.wav: nicht funktionieren. Das sind aber keine Features, die wir jetzt gerade benÃ¶tigen. Von dem her kÃ¶nnen wir diesen Error einfach getrost ignorieren. Die Installation ist abgeschlossen.\n",
      "ğŸ“ segment_0179.wav: gehen wir zurÃ¼ck in Visual Studio Code. Schauen wir mal kurz, hier hat sich etwas verÃ¤ndert. Zum einen wurden in unserer Package Chasen ein neues Feld hinzugefÃ¼gt, nÃ¤mlich diese Dev-Dependencies. Das ist das, was ich mit dem Befehl \"--save dev-\"\n",
      "ğŸ“ segment_0180.wav: veranlasst habe und das schreibt letztendlich einfach alle AbhÃ¤ngigkeiten unseres Projekts oder alle EntwicklungsabhÃ¤ngigkeiten.\n",
      "ğŸ“ segment_0181.wav: diese Package chasen. Ich will jetzt nicht zu sehr ins Detail gehen, weil das ist ja ein Kurs Ã¼ber React und nicht Ã¼ber NPM.\n",
      "ğŸ“ segment_0182.wav: dass ihr versteht warum ich diesen Fehler angegeben habe. Es ist auch eine Package LogJSON generiert worden, das ist sozusagen ein Logbuch aller derer Pakete, die wir installiert haben mit genauen Funktionen und zu guter Letzt wurde hier Node Modules angelegt, das ist der\n",
      "ğŸ“ segment_0183.wav: in denen die Pakete, die wir installiert haben, tatsÃ¤chlich heruntergeladen wurden. Wenn wir das mal kurz aufmachen.\n",
      "ğŸ“ segment_0184.wav: sehen wir hier natÃ¼rlich deutlich mehr als wir installiert haben. Das liegt einfach dran, dass Babel selbst ja auch AbhÃ¤ngigkeiten hat, die es wieder\n",
      "ğŸ“ segment_0185.wav: herum Ã¼ber eine Package JSON definiert und alle diese AbhÃ¤ngigkeiten installiert.\n",
      "ğŸ“ segment_0186.wav: oder npm fÃ¼r uns dann gleich mit, dass wir das nicht hÃ¤ndisch machen mÃ¼ssen. Aber wir sehen auch, add-babel-cli wurde installiert, add-babel-core wurde installiert.\n",
      "ğŸ“ segment_0187.wav: installiert.\n",
      "ğŸ“ segment_0188.wav: Und weiter unten, at Babel Presaved Reakt, ist dann auch in unserem Projekt vorhanden. Nun mÃ¼ssen wir Babel noch entsprechend ein wenig konfigurieren.\n",
      "ğŸ“ segment_0189.wav: beziehungsweise auch ausfÃ¼hren. Denn aktuell wÃ¼sste Babi ja noch nicht, was es tun soll.\n",
      "ğŸ“ segment_0190.wav: und Babel weiÃŸ aktuell auch noch nicht, welche WÃ¶rterbÃ¼cher es einsetzen soll. Fangen wir mit dem WÃ¶rterbuch an. Wir kÃ¶nnen Babel ganz einfach konfigurieren, indem wir nochmal eine neue Datei anlegen, die sich pro ...\n",
      "ğŸ“ segment_0191.wav: Punkt.\n",
      "ğŸ“ segment_0192.wav: In dieser Datei kÃ¶nnen wir valides JSON schreiben, also das ist eigentlich nur eine JSON Datei, auch wenn sie nicht auf JSON endet. Wir kÃ¶nnen dort ein Objekt anlegen und das Feld Presets befÃ¼llen.\n",
      "ğŸ“ segment_0193.wav: und dort nun in einem Array alle die Presets reinschreiben, die bar...\n",
      "ğŸ“ segment_0194.wav: fÃ¼r uns verwenden. Also sprich alle diese WÃ¶rterbÃ¼cher, die wir Ã¼bersetzen wollen. In unserem Fall ist das nur eines, nÃ¤mlich Babel.\n",
      "ğŸ“ segment_0195.wav: preset wirkt. Das ist der erste Schritt. Im zweiten Schritt mÃ¼ssen wir nun aus dieser App.js eine App.js\n",
      "ğŸ“ segment_0196.wav: Datei machen. Denn wir haben hier ja tatsÃ¤chlich nicht mehr valides JavaScript stehen, deswegen ist das auch keine JavaScript Datei mehr, sondern es ist jetzt eine JSX Datei, weil wir hier JSX eingefÃ¼gt haben. Und nun mÃ¼ssen wir Babel diese Datei...\n",
      "ğŸ“ segment_0197.wav: fÃ¼r uns Ã¼bersetzen lassen. Das kÃ¶nnen wir nun eben mit barb's CLI Ã¼ber die command line tun.\n",
      "ğŸ“ segment_0198.wav: Und zwei MÃ¶glichkeiten. Wir kÃ¶nnten hier auch wieder NPX einsetzen, um quasi Babel direkt auszufÃ¼hren. Wir haben aber die Babel CLI ja auch bei uns installiert.\n",
      "ğŸ“ segment_0199.wav: und das ganze nÃ¤mlich in Node Modules, dem sogenannten Bin oder Binary Folder, gibt es den Befehl Babel. Dieser Befehl\n",
      "ğŸ“ segment_0200.wav: erwartet drei Parameter. Zum einen das Surs-Verzeichnis oder das Verzeichnis, das Babel fÃ¼r uns Ã¼bersetzen soll. In unserem Fall ist das tatsÃ¤chlich Surs. Es erwartet den Parameter M.\n",
      "ğŸ“ segment_0201.wav: Das ist die Stelle, wo Babel die kombinierten oder die Ã¼bersetzten Dateien hinschreiben soll. Und das machen wir bei uns jetzt einfach mal in ein Verzeichnis, dass wir\n",
      "ğŸ“ segment_0202.wav: Lippnen. Wenn wir mit diesen Befehlungen ausfÃ¼hren,\n",
      "ğŸ“ segment_0203.wav: Quittiert uns Babel das mit einer erfolgreichen Meldung, dass es uns eine Datei erfolgreich kompiliert hat oder Ã¼bersetzt hat. Wenn wir zurÃ¼ck ins Projektverzeichnis springen, sehen wir auch, dass der Lipfolder angelegt wurde und hier.\n",
      "ğŸ“ segment_0204.wav: entsprechend analog zu unserer App.jsx eine App.js-Datei angelegt wurde. Und die kÃ¶nnen wir uns auch anschauen. Und siehe da. Aus unserem.jsx ist nichts anderes geworden als ein React Create Element auf\n",
      "ğŸ“ segment_0205.wav: der relativ oder nicht noch relativ, sondern ziemlich gleich aussieht, wie das, was wir davor haben.\n",
      "ğŸ“ segment_0206.wav: hindisch eingegeben haben. Das ist tatsÃ¤chlich die gesamte Magie hinter GSX und Babel. Es macht nichts anderes als die Teile die HTML...\n",
      "ğŸ“ segment_0207.wav: und unserem JSExit in ein React.CreateElement zu Ã¼bersetzen. Nun mÃ¼ssen wir, damit das auch funktioniert, noch eine kleine Ã„nderung in unserer Index-HTML vornehmen, weil wir jetzt nicht mehr die App.js aus unserem Source auswÃ¤hlen.\n",
      "ğŸ“ segment_0208.wav: ausliefern oder die App JSX, sondern wir mÃ¼ssen ja die Ã¼bersetzte Variante\n",
      "ğŸ“ segment_0209.wav: unserer App ausliefern. Dementsprechend Ã¤ndern wir das hier einfach auf lib. Und wenn wir nun nochmal einen LAP Server starten.\n",
      "ğŸ“ segment_0210.wav: und zurÃ¼ck auf unsere Webseite.\n",
      "ğŸ“ segment_0211.wav: Zeit navigieren. Sehen wir, wir haben ein erstes Rigged Element.\n",
      "ğŸ“ segment_0212.wav: Weil wir hier noch das alte Element auch eingebunden haben, wir wollen jetzt aber eigentlich hier das die erste ChessX-Komponente einbinden. Dementsprechend mÃ¼ssen wir das hier\n",
      "ğŸ“ segment_0213.wav: Wir wollen nun MyJSX Element rendern. Wir mÃ¼ssen das ganze jetzt natÃ¼rlich von Babel nochmal neu Ã¼bersetzen lassen. Wenn wir jetzt den Web-Server starten...\n",
      "ğŸ“ segment_0214.wav: sollten wir tatsÃ¤chlich sehen, dass wir unsere ersten JSX-Komponente erfolgreich im Browser gewendet haben. Das ist super!\n",
      "ğŸ“ segment_0215.wav: zum Abschluss kommen, mÃ¶chte ich euch noch einen kleinen Tipp mitgeben, denn diesen Befehl, den wir hier gerade gesehen haben, NodeModules.bin.barbisource ist schwer zu merken und ist auch nicht sonderlich schÃ¶n einzutippen. Da kÃ¶nnen wir uns mit NPL\n",
      "ğŸ“ segment_0216.wav: und mit npm scripts ein wenig Abfehlung verschaffen. Scripts erlaubt uns es nÃ¤mlich Scripte unter einem sogenannten alias oder einem anderen Namen vorzudefinieren. Wenn wir jetzt also hier sowas wie compile schreiben und dort\n",
      "ğŸ“ segment_0217.wav: den Befehl.\n",
      "ğŸ“ segment_0218.wav: minus minus out your blip, Gefolgt von einem Komma reinschreiben, kÃ¶nnen wir diesen sehr aufwÃ¤ndigen Befehl deutlich\n",
      "ğŸ“ segment_0219.wav: leichter in unserer Command Line ausfÃ¼hren. Ganz kurz, wir kÃ¶nnen uns hier das Node-Module Spin sparen.\n",
      "ğŸ“ segment_0220.wav: weil die Scripts von npm per Default dieses Binary-Verzeichnis einbinden. Das heiÃŸt, hier kÃ¶nnen wir auf diesen ganzen vorherigen Pfad verzichten und einfach Babel direkt ausfÃ¼hren. Und nun kÃ¶nnen wir einfach Ã¼ber den Befehl...\n",
      "ğŸ“ segment_0221.wav: in unserem aktuellen Verzeichnis npm run, jedes Script, das wir definiert haben, ausfÃ¼hren. In unserem Fall nur compile. Wie wir sehen, wurde Babel wieder ausgefÃ¼hrt. Um uns, unsere ...\n",
      "ğŸ“ segment_0222.wav: oder JSX-Dateien zu Ã¼bersetzen. Letztendlich kann hier in ...\n",
      "ğŸ“ segment_0223.wav: scripts jedes valide CLI-Commandos.\n",
      "ğŸ“ segment_0224.wav: eingefÃ¼gt werden. Und wir kÃ¶nnen so die fÃ¼r unser Projekt relevanten C&I Command sehr sehr einfach und sehr sehr Ã¼berstiftig...\n",
      "ğŸ“ segment_0225.wav: in der Package schÃ¤fen. Das ist ein kleiner Trick, der in vielen Projekten auch sehr...\n",
      "ğŸ“ segment_0226.wav: eingesetzt wird. Das kÃ¶nnen wir zum Beispiel als letztes noch erweitern, indem wir hier npx server eintragen und wir uns somit nicht mehr npx server eintippen mÃ¼ssen, sondern nun um unseren Web Server zu starten.\n",
      "ğŸ“ segment_0227.wav: und die Website auszuliefern, npm run start eingeben kÃ¶nnen. Und nun ist unser Webserver wieder verfÃ¼gbar. Und das war es auch schon.\n",
      "ğŸ“ segment_0228.wav: heutigen Folge. Nochmal ein kurzes Review. Was haben wir gemacht? Wir haben das lokale Setup mit Visual Studio Code und NPM vorbereitet. Ich habe einen ersten Einblick in die Toolkit.\n",
      "ğŸ“ segment_0229.wav: NPM, NPX und Babel gegeben und wir haben diese auch schon live eingesetzt. Wir haben React eingebunden mit der Variante CDN oder Content Delivery Network.\n",
      "ğŸ“ segment_0230.wav: und wir haben mit React Element und JSX eine erste Hello World Applikation von React implementiert. Da haben wir schon einen groÃŸen Schritt gemacht. Das nÃ¤chste Mal wird es ein\n",
      "ğŸ“ segment_0231.wav: noch spannender. Da werden wir nÃ¤mlich React Components vorstellen und einsetzen und mit den React Components die Renderfunktion, Props und dann noch ein paar\n",
      "ğŸ“ segment_0232.wav: Besonderheiten von GSX kennenlernen. An dieser Stelle bedanke ich mich recht herzlich, dass ihr dieses Video angesehen habt. Ich hoffe, ihr konntet etwas lernen. Bei Fragen, Feedback oder sonstigen WÃ¼nschen und Anregungen meldet euch gerne an.\n",
      "ğŸ“ segment_0233.wav: bei uns Ã¼ber diese KanÃ¤le hello.atthenativefab.io per E-Mail oder auch auf Twitter und GitHub. Und ich wÃ¼nsche euch jetzt noch einen schÃ¶nen Tag und bis zur nÃ¤chsten!\n",
      "ğŸ“ segment_0234.wav: nÃ¤chsten Folge.\n",
      "ğŸ“ segment_0235.wav: TschÃ¼ss!\n",
      "âœ… Metadata saved to: metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import csv\n",
    "\n",
    "def transcribe_and_generate_metadata(audio_folder, metadata_file=\"metadata.csv\", model_size=\"medium\"):\n",
    "    # Initialize Whisper model\n",
    "    model = whisper.load_model(model_size, download_root=\"/home/ahmet/.cache/whisper\", device=\"cuda\")\n",
    "\n",
    "    # Prepare CSV file\n",
    "    with open(metadata_file, mode='w', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter='|')\n",
    "        \n",
    "        # Process each WAV file\n",
    "        for wav_file in sorted(os.listdir(audio_folder)):\n",
    "            if wav_file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(audio_folder, wav_file)\n",
    "\n",
    "                # Transcribe audio\n",
    "                result = model.transcribe(file_path, language=\"de\")  # Set language accordingly\n",
    "                transcript = result.get(\"text\", \"\").strip()\n",
    "\n",
    "                # Add entry to CSV\n",
    "                writer.writerow([wav_file, transcript, transcript])\n",
    "                print(f\"ğŸ“ {wav_file}: {transcript}\")\n",
    "\n",
    "    print(f\"âœ… Metadata saved to: {metadata_file}\")\n",
    "\n",
    "# Run transcription\n",
    "audio_folder = \"segmented_audio\"\n",
    "transcribe_and_generate_metadata(audio_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed metadata.csv! Saved as metadata_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Paths\n",
    "input_csv = \"audio_dataset_2/metadata.csv\"\n",
    "output_csv = \"audio_dataset_2/metadata_fixed.csv\"\n",
    "\n",
    "# Fix .wav extensions\n",
    "with open(input_csv, \"r\", encoding=\"utf-8\") as infile, open(output_csv, \"w\", encoding=\"utf-8\", newline=\"\") as outfile:\n",
    "    reader = csv.reader(infile, delimiter=\"|\")\n",
    "    writer = csv.writer(outfile, delimiter=\"|\")\n",
    "\n",
    "    for row in reader:\n",
    "        # Remove '.wav' from first column if it exists\n",
    "        filename = row[0].replace(\".wav\", \"\")\n",
    "        writer.writerow([filename, row[1], row[2]])\n",
    "\n",
    "print(\"âœ… Fixed metadata.csv! Saved as metadata_fixed.csv\")\n",
    "\n",
    "# Optional: Replace the old file with the new one\n",
    "import os\n",
    "os.replace(output_csv, input_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
