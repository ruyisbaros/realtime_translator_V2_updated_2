{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wollen wir das Ganze einfach mal ausführen → ˈwo.lle.n ˈwi.ʁ ˈda.s ˈga.ntse ˈa.ɪ.̯nfa.x ˈma.l ˈa.ʊ̯sfʏ.hʁe.n\n",
      "Das ist ein Test → ˈda.s ˈi.ʃt ˈa.ɪ.̯n ˈte.ʃt\n",
      "Können wir den Text ins IPA umwandeln → ˈkœ.nne.n ˈwi.ʁ ˈde.n ˈte.xt ˈi.ns ˈi.pa ˈu.mwa.nde.ln\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def german_to_ipa(text):\n",
    "    ipa_mapping = {\n",
    "        \"sch\": \"ʃ\", \"ch\": \"x\", \"z\": \"ts\", \"j\": \"j\", \"r\": \"ʁ\", \"ng\": \"ŋ\",\n",
    "        \"au\": \"aʊ̯\", \"ei\": \"aɪ̯\", \"eu\": \"ɔʏ̯\", \"äu\": \"ɔʏ̯\", \"sp\": \"ʃp\", \"st\": \"ʃt\",\n",
    "        \"ä\": \"ɛ\", \"ö\": \"œ\", \"ü\": \"ʏ\", \"ß\": \"s\", \"ph\": \"f\", \"qu\": \"kv\"\n",
    "    }\n",
    "\n",
    "    words = text.lower().split()\n",
    "    ipa_words = []\n",
    "\n",
    "    for word in words:\n",
    "        ipa_word = word\n",
    "        for key, val in ipa_mapping.items():\n",
    "            ipa_word = ipa_word.replace(key, val)\n",
    "\n",
    "        # Insert syllable boundaries and primary stress for the first syllable\n",
    "        ipa_word = re.sub(r\"([aeiouäöüɪɛœʏ])\", r\"\\1.\", ipa_word)  # syllables after vowels\n",
    "        ipa_word = re.sub(r\"\\.$\", \"\", ipa_word)  # remove trailing syllable\n",
    "        ipa_word = \"ˈ\" + ipa_word  # add primary stress\n",
    "\n",
    "        ipa_words.append(ipa_word)\n",
    "\n",
    "    return \" \".join(ipa_words)\n",
    "\n",
    "# Test the function\n",
    "sentences = [\n",
    "    \"Wollen wir das Ganze einfach mal ausführen\",\n",
    "    \"Das ist ein Test\",\n",
    "    \"Können wir den Text ins IPA umwandeln\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    ipa = german_to_ipa(sentence.lower())\n",
    "    print(f\"{sentence} → {ipa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ IPA conversion completed. Saved to audio_dataset_2/metadata_ipa.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def convert_metadata_to_ipa(input_file='audio_dataset_2/metadata.csv', output_file='audio_dataset_2/metadata_ipa.csv'):\n",
    "    \"\"\"Converts the second column of metadata.csv to IPA and saves it\"\"\"\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        reader = csv.reader(infile, delimiter='|')\n",
    "        writer = csv.writer(outfile, delimiter='|')\n",
    "\n",
    "        for row in reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "\n",
    "            original_text = row[1]\n",
    "            ipa_text = german_to_ipa(original_text)\n",
    "\n",
    "            new_row = [row[0], f\"/{ipa_text}/\", row[2]]\n",
    "            writer.writerow(new_row)\n",
    "\n",
    "    print(f\"✅ IPA conversion completed. Saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Run the conversion\n",
    "convert_metadata_to_ipa()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Segmenting audio into chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_766575/2904774351.py:11: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(input_audio, sr=22050)\n",
      "/home/ahmet/anaconda3/envs/tts_env/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: audio_dataset_2/wavs/segment_000.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_001.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_002.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_003.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_004.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_005.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_006.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_007.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_008.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_009.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_010.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_011.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_012.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_013.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_014.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_015.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_016.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_017.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_018.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_019.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_020.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_021.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_022.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_023.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_024.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_025.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_026.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_027.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_028.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_029.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_030.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_031.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_032.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_033.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_034.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_035.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_036.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_037.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_038.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_039.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_040.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_041.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_042.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_043.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_044.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_045.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_046.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_047.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_048.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_049.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_050.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_051.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_052.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_053.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_054.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_055.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_056.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_057.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_058.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_059.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_060.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_061.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_062.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_063.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_064.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_065.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_066.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_067.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_068.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_069.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_070.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_071.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_072.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_073.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_074.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_075.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_076.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_077.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_078.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_079.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_080.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_081.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_082.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_083.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_084.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_085.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_086.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_087.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_088.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_089.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_090.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_091.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_092.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_093.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_094.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_095.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_096.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_097.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_098.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_099.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_100.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_101.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_102.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_103.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_104.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_105.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_106.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_107.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_108.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_109.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_110.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_111.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_112.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_113.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_114.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_115.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_116.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_117.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_118.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_119.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_120.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_121.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_122.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_123.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_124.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_125.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_126.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_127.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_128.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_129.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_130.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_131.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_132.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_133.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_134.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_135.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_136.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_137.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_138.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_139.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_140.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_141.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_142.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_143.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_144.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_145.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_146.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_147.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_148.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_149.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_150.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_151.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_152.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_153.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_154.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_155.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_156.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_157.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_158.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_159.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_160.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_161.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_162.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_163.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_164.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_165.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_166.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_167.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_168.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_169.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_170.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_171.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_172.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_173.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_174.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_175.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_176.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_177.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_178.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_179.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_180.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_181.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_182.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_183.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_184.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_185.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_186.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_187.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_188.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_189.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_190.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_191.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_192.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_193.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_194.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_195.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_196.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_197.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_198.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_199.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_200.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_201.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_202.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_203.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_204.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_205.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_206.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_207.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_208.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_209.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_210.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_211.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_212.wav (15s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_213.wav (5s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_214.wav (10s)\n",
      "✅ Saved: audio_dataset_2/wavs/segment_215.wav (15s)\n",
      "🎯 Audio segmentation completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "input_audio = \"org.mp4\"\n",
    "output_dir = \"audio_dataset_2/wavs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def segment_audio(input_audio, output_dir, segment_durations=[5, 10, 15]):\n",
    "    print(\"🎯 Segmenting audio into chunks...\")\n",
    "    y, sr = librosa.load(input_audio, sr=22050)\n",
    "    total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "    current_position = 0\n",
    "    segment_count = 0\n",
    "\n",
    "    while current_position < total_duration:\n",
    "        duration = segment_durations[segment_count % len(segment_durations)]\n",
    "        end_position = min(current_position + duration, total_duration)\n",
    "\n",
    "        # Extract chunk\n",
    "        chunk = y[int(current_position * sr):int(end_position * sr)]\n",
    "        file_path = os.path.join(output_dir, f\"segment_{segment_count:03d}.wav\")\n",
    "\n",
    "        # Save chunk\n",
    "        sf.write(file_path, chunk, sr)\n",
    "        print(f\"✅ Saved: {file_path} ({duration}s)\")\n",
    "        current_position = end_position\n",
    "        segment_count += 1\n",
    "\n",
    "    print(\"🎯 Audio segmentation completed!\")\n",
    "\n",
    "segment_audio(input_audio, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmet/anaconda3/envs/tts_env/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 7.75 GiB of which 24.44 MiB is free. Including non-PyTorch memory, this process has 7.17 GiB memory in use. Of the allocated memory 7.03 GiB is allocated by PyTorch, and 19.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedium\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/ahmet/.cache/whisper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m input_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_dataset_2/wavs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m metadata_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_dataset_2/metadata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/whisper/__init__.py:160\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alignment_heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_alignment_heads(alignment_heads)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tts_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 7.75 GiB of which 24.44 MiB is free. Including non-PyTorch memory, this process has 7.17 GiB memory in use. Of the allocated memory 7.03 GiB is allocated by PyTorch, and 19.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"medium\", download_root=\"/home/ahmet/.cache/whisper\")\n",
    "input_dir = \"audio_dataset_2/wavs\"\n",
    "metadata_path = \"audio_dataset_2/metadata.csv\"\n",
    "\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f_meta:\n",
    "    for file in sorted(os.listdir(input_dir)):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(input_dir, file)\n",
    "            print(f\"🎙️ Transcribing {file}...\")\n",
    "\n",
    "            try:\n",
    "                result = model.transcribe(file_path)\n",
    "                text = result['text'].strip()\n",
    "                f_meta.write(f\"{file}|{text}|{text}\\n\")\n",
    "                print(f\"✅ {file}: {text[:50]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Failed to transcribe {file}: {e}\")\n",
    "\n",
    "print(\"🎯 Transcription completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmet/anaconda3/envs/tts_env/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 segment_0001.wav: Hallo und herzlich willkommen zur zweiten Folge von Einführung in React mit dem Thema React Setup. Noch einmal kurz zu mir, mein Name ist David Losert, ich bin Software Engineer und seit über zehn Jahren im Web unterwegs und arbeite nun auch bereits seit vier Jahren.\n",
      "📝 segment_0002.wav: Jahren mit React. Neben React mache ich die Arbeit mit JavaScript, TypeScript, Node.js, Linux-Servern, Docker und AWS. Die heutige Folge dreht sich also nun komplett darum, eine Entwicklungs-\n",
      "📝 segment_0003.wav: Umgebung aufzusetzen und dort eine erste Reaction.\n",
      "📝 segment_0004.wav: Hello World Applikation zu implementieren. Wenn wir uns kurz erinnern, in der letzten Folge habe ich die Geschichte und Prinzipien von React kurz vorgestellt und einen ersten theoretischen Einblick auf die Geschichte und Prinzipien von React.\n",
      "📝 segment_0005.wav: Blick in den Virtual Dom und in JSX gegeben. Das habe ich an dieser Stelle auch einmal kurz visualisiert. Wir erinnern uns der Virtual Dom.\n",
      "📝 segment_0006.wav: ist eine Abstraktion, die React verwendet, um den DOM zu synchronisieren. Und der Virtual DOM erlaubt uns zum einen das Deklarative programmieren.\n",
      "📝 segment_0007.wav: und zum anderen gibt es uns einige Performance-Vorteile. In dieser Folge wollen wir nun eben also eine Entwicklungsumgebung auf der\n",
      "📝 segment_0008.wav: Ich nutze dazu Visual Studio Code. Wir werden uns ...\n",
      "📝 segment_0009.wav: ein erstes Toolset anschauen mit NPM, NPX und Babel.\n",
      "📝 segment_0010.wav: was uns bei der Entwicklung von React-Applikationen hilft. Und wir werden natürlich...\n",
      "📝 segment_0011.wav: eine erste Reakt-Applikation implementieren und nutzen dazu das Reakt Element, ein atomarer Building Block von Reakt und JSX. In dieser Stelle werdet ihr vielleicht kurz aufmerken, ich habe das letzte mal viele von Reakt...\n",
      "📝 segment_0012.wav: Reakt-Components gesprochen. Reakt-Components sind nicht zu verwechseln mit Reakt-Element. Ich stelle nun aber in dieser Folge zuerst Reakt-Element vor, weil es sozusagen\n",
      "📝 segment_0013.wav: die Grundlage ist oder der atomare Baustein, der tatsächlich atomare Baustein von React. Und React Element nimmt uns aus JSX auch so ein wenig die Magie. Denn wenn man JSX das erste Ball sieht, kann man sich schnell fragen...\n",
      "📝 segment_0014.wav: wie funktioniert das eigentlich hinter den Kulissen? Und React Element ist letztendlich das, was hinter den Kulissen steckt.\n",
      "📝 segment_0015.wav: am Ende der Folge dann auch einfach sehen. Bevor wir loslegen, möchte ich euch ermutigen, alle Code-Beispiele und praktischen Hands-on-Teile, die wir in dieser Folge machen, nachzuprogrammieren. Der praktische Einsatz\n",
      "📝 segment_0016.wav: ist einfach der beste, um eine neue Technologie zu lernen.\n",
      "📝 segment_0017.wav: entweder machen, indem ihr nebenher programmiert und die Folge immer wieder pausiert oder aber\n",
      "📝 segment_0018.wav: durch die Folge einmal komplett an und programmiert das Beispiel im Nachhinein alleine. Wir werden den gesamten Code auch auf GitHub zur Verfügung stellen. Das kann dann ein wenig als Orientierung dienen. Dabei geht einfach auf GitHub.\n",
      "📝 segment_0019.wav: und sucht dort nach tech-lounge-surject und ihr solltet das entsprechende Repository finden. Das ist aktuell hier noch leer, weil ich den Code natürlich erst nach dieser Folge hochladen werde.\n",
      "📝 segment_0020.wav: würde ich sagen legen wir auch einfach schon mal los. Um unsere Umgebung vorzubereiten, müssen ein paar Schritte unternommen werden.\n",
      "📝 segment_0021.wav: Die haben jetzt mit React erstmal noch nichts zu tun. Zum einen müsst ihr euch Visual Studio Code installieren. Oder müsst ihr nicht, wenn ihr einen anderen Editor bevorzugt.\n",
      "📝 segment_0022.wav: ist das auch vollkommen okay. Ich arbeite nur hier mit Visual Studio Code, weil ich diese Idee doch recht gerne habe. Sie bittet mir einige Unterstützung, zum Beispiel Codevervollständigung, was wir nachher auch sehen werden.\n",
      "📝 segment_0023.wav: einer Entwicklungsumgebung Visual Studio Code brauchen wir Node.js und NPM.\n",
      "📝 segment_0024.wav: Da erkläre ich auch gleich ein paar Worte zu. Und wir müssen natürlich ein...\n",
      "📝 segment_0025.wav: Projektordner anlegen und unsere Umgebung vorbereiten mit ein paar wenigen Commands in der Kommandozeile. Ein paar Worte zu NPM, falls ihr das noch nicht gehört habt. NPM ist ein Paketmanager.\n",
      "📝 segment_0026.wav: für JavaScript Tools, Bibliotheken und Frameworks und erlaubt uns über ein\n",
      "📝 segment_0027.wav: eine einfache Command Line Interface, das installieren und verwalten eben dieser Tool.\n",
      "📝 segment_0028.wav: Bibliotheken und Frameworks. Das ist ein einfacher Befehl wie npm install.\n",
      "📝 segment_0029.wav: der uns Abhängigkeiten unserer Projekt installiert. Bei NPM dreht sich eigentlich alles um die Package Chasing.\n",
      "📝 segment_0030.wav: eine Datei, die wir in unserem Projektordner im Bootfolder machen.\n",
      "📝 segment_0031.wav: erstellen werden und in dieser Package JSON sind Abhängigkeiten beschrieben, Skripte und auch ...\n",
      "📝 segment_0032.wav: Projekt Metadaten.\n",
      "📝 segment_0033.wav: das NPM mitbringt ist NPX.\n",
      "📝 segment_0034.wav: Und das ermöglicht uns die Ausführung all dieser JavaScript Tools Bibliotheken und Frameworks ohne eine Installation.\n",
      "📝 segment_0035.wav: Das können wir zum Beispiel nutzen, um einen lokalen Webserver zu starten, der unser Testprojekt ausliefert.\n",
      "📝 segment_0036.wav: und das werden wir auch tun. Und wir werden dazu den Webserver Servor verwenden. Das ist kein Schreibfehler. Dieses Paket heißt wirklich so. NPX Servor startet mit diesem Befehl einen lokalen\n",
      "📝 segment_0037.wav: Web Server im aktuellen Verzeichnis. Wir haben hier noch das Argument minus minus reload. Das erlaubt uns oder das erlaubt\n",
      "📝 segment_0038.wav: dem Server alle Dateien, die in unserem Projekt sich tummeln, zu beobachten und bei einer Änderung unseren Browser automatisch neu zu laden. Das ist während der Entwicklung sehr bequem.\n",
      "📝 segment_0039.wav: weil es uns das Neuladen der Seite händisch erspart, indem wir entweder F5 drücken oder hier über den Reload-Button die Seite neu laden. Wenn wir diesen Befehl per Default ausführen, liefert er eine Index-Handung.\n",
      "📝 segment_0040.wav: HTML, welche wir auch gleich erstellen werden, im aktuellen Ordner unter der Adresse htdp localhost 8080 aus. Und nun um euch auch mal zu zeigen, wie ein MPM-Paket auf der Registry ausschaut.\n",
      "📝 segment_0041.wav: hier unter npm.js.com habt ihr eine Suche, in der ihr alle...\n",
      "📝 segment_0042.wav: Pakete, die es so gibt, suchen könnt. Und für jedes Paket gibt es dann auch eine Seite mit einer Beschreibung und Installationsanweisungen.\n",
      "📝 segment_0043.wav: was man halt zu diesem Paket wissen muss. Wollen wir das Ganze einfach mal ausführen? Dazu gehen wir also in unserer Command Line und legen uns...\n",
      "📝 segment_0044.wav: erstmal einen Ordner an. Den nenne ich hier einfach mal Einführung Reakt. Jetzt sieht man, dass ich den zuvor schon angelegt habe.\n",
      "📝 segment_0045.wav: Deswegen bringt er mir hier einen Error. Bei euch wird das dann funktionieren. Wir können einfach in diesem Ordner reinnamigieren und wir werden den Befehl npm init ausfüllen. npm init erzeugt uns eben eine Package JSON, eine Initialen und spart uns so ein wenig.\n",
      "📝 segment_0046.wav: das von Hand zu tun, indem es uns über die Kommandozeile ein paar Fragen...\n",
      "📝 segment_0047.wav: stellt. Als allererstes will es den Package-Name von uns wissen, den es per Default-Package\n",
      "📝 segment_0048.wav: aus dem aktuellen Ordner einfach herauszieht. Einfach umreakt ist in diesem Fall ok. Die Version ist für uns jetzt auch erstmal ok. Wir erinnern uns kurz an die letzte Folge.\n",
      "📝 segment_0049.wav: Semper, Semantik Verschmung, kommt bei NPM ganz stark zum Einsatz. Eine Description, da können wir uns einfach irgendeinen Freitext überlegen. Das ist eine Einführung in React zum Beispiel.\n",
      "📝 segment_0050.wav: Der Entry Point werden wir nachher sehen.\n",
      "📝 segment_0051.wav: Testcommand wir haben keine\n",
      "📝 segment_0052.wav: automatisierten Test, deswegen lassen wir das leer. Wir haben auch noch kein Git Repository eingerichtet.\n",
      "📝 segment_0053.wav: erstmal keine Keywords vergeben. Den Author können wir uns selber reinschreiben.\n",
      "📝 segment_0054.wav: und eine Lizenz ist bei privaten Testprojekten auch eher nicht ganz so wichtig. Ich nehme hier in der Regel immer MIT.\n",
      "📝 segment_0055.wav: aber im Prinzip auch auf ISC lassen. NPM fragt uns das nochmal, ob alle unsere Eingaben korrekt waren und wird uns eben diese Chasing-Datei\n",
      "📝 segment_0056.wav: als Package JSON im aktuellen Verzeichnis anlegen. In unserem Fall ist das jetzt ok, deswegen yes. Als nächstes öffnen wir nun diesen Ordner in unserer Entwicklungsumgebung. In meinem Fall ist das eben Bishul Studio Code.\n",
      "📝 segment_0057.wav: Das können wir ganz einfach machen, indem wir hier auf File Open gehen.\n",
      "📝 segment_0058.wav: zum entsprechenden Ort navigieren und dann auf öffnen drücken. Und jetzt sehen wir, dass uns eben eine Package-Json generiert wurde, in der all die Felder, die wir vorher befragen haben,\n",
      "📝 segment_0059.wav: beantwortet haben, entsprechend eingetragen sind. Als nächsten Schritt wollen wir uns nun also eine noch eine Index HTML anlegen, also eine initiale HTML-Seite, die ausgeliefert werden kann.\n",
      "📝 segment_0060.wav: Das machen wir über den New File, index.html. Und dort schreiben wir einfach eine standardmäßige HTML-Datei, angefangen mit dem Doctype.\n",
      "📝 segment_0061.wav: Und hier haben wir jetzt schon ein tolles Feature von Visual Studio Code gesehen, die Autovervollständigung. Ich lösche das nochmal.\n",
      "📝 segment_0062.wav: das Codes eingebe, den ich hier erzeugen will, bietet mir Visual Studio Code schon eine Vorauswahl an. Wenn ich diese bestätige entweder über Enter oder indem ich trau...\n",
      "📝 segment_0063.wav: klickte, füllt es mir das entsprechend aus. Im klassischen HTML-Dokument kommt das nächste HTML. Wir brauchen einen Het oder einen Het-Tag, in welchem wir dann einen Titel vergeben.\n",
      "📝 segment_0064.wav: können. Das nennen wir mal Einführung in Reakt. Und wir brauchen ein Buddy und da wollen wir jetzt einfach wieder suchen.\n",
      "📝 segment_0065.wav: üblich ist bei einem Code Beispiel mit Hello World anfangen. Wenn ich nur noch Speichern drücke, nicht wundern, das ist auch ein Feature von Visual Studio Code.\n",
      "📝 segment_0066.wav: Das ist mir automatisch mein Dokument.\n",
      "📝 segment_0067.wav: nach gewissen Kriterien formatiert. Dementsprechend kann es sein, dass sie manchmal ein Zeichen...\n",
      "📝 segment_0068.wav: Umbruch hinzugefügt wird. Das ist einfach sehr bequem, das ist immer alles.\n",
      "📝 segment_0069.wav: einheitlich formatiert wird. So, nun haben wir eine Index-HTML erstellt. Diese wollen wir jetzt natürlich noch über einen Web-Server ausliefern, um unsere Entwicklungsumgebung zu vervollständigen. Und wie vorher besprochen, nehmen wir dazu NPE.\n",
      "📝 segment_0070.wav: ein npx servo minus minus reload das dauert kurz und gibt uns dann hier auch entsprechend zurück dass nun unter htp localhost\n",
      "📝 segment_0071.wav: 8080 die aktuelle Website oder der aktuelle Ordner ausgeliefert wird und standardmäßig eben diese Index HTML ausgeliefert wird und das sehen wir auch in dem wir zum Browser\n",
      "📝 segment_0072.wav: navigieren und entsprechend diese URL eingeben.\n",
      "📝 segment_0073.wav: Und hier da unsere Hello World Index HTML wird ausgeliefert. Eine kleine Unschönheit sehen wir hier noch. Einführung in React. Das Ü hat er irgendwie noch nicht erkannt. Dazu müssen wir in dem HTML im Het-Teil...\n",
      "📝 segment_0074.wav: noch das Charset auf UTF-8 setzen. Das geht auch ganz einfach, indem wir ja ein Neta-Charset Felt-UTF-8 eingeben. Wir drücken Speichern und wenn wir nun zur Brücke\n",
      "📝 segment_0075.wav: auf die Website navigieren, sehen wir, dass das Reload Flag von Server schon seinen Job getan hat, die Seite wurde automatisch neu geladen und das Ü wird hier nun korrekt dargestellt. Und damit haben wir im Wesentlichen schon eine laute\n",
      "📝 segment_0076.wav: Entwicklungsungebung, in der wir nun React entwickeln können. Dazu nun wieder ein bisschen Theorie. Es gibt mehrere ...\n",
      "📝 segment_0077.wav: Methoden, wie wir React nun in unser Projekt installieren können oder wie wir auch React aufsetzen können. Die einfachste Methode sind Online Playgrounds. Online Playgrounds sind\n",
      "📝 segment_0078.wav: im Prinzip Entwicklungsumgebung direkt im Browser. React bietet selber auf seiner Seite Dokumentationen, einen Online-Breaker und an, zum Beispiel CodePen. Das können wir uns auch mal ganz kurz anschauen. Wir gehen auf Get Started, drücken, Try React.\n",
      "📝 segment_0079.wav: sehen wir hier die Online-Breakdowns. Wenn wir da zum Beispiel auf CodePen navigieren,\n",
      "📝 segment_0080.wav: werden wir gleich weiter geladen.\n",
      "📝 segment_0081.wav: und haben nun hier ebenfalls eine Hello World Applikation von React, die wir entsprechend auch bearbeiten können.\n",
      "📝 segment_0082.wav: Command-Enter wird die Seite nun aktualisiert. Das ist wie gesagt super, um React auszuprobieren.\n",
      "📝 segment_0083.wav: bei euch lokal nicht funktioniert, nachzustellen. Aber wenn wir langfristig Projekte entwickeln, wollen wir natürlich irgendwie den Code, den wir produzieren, auch richtig abspeichern.\n",
      "📝 segment_0084.wav: ist in diesen Online-Playgrounds eher schwierig möglich. Dementsprechend wollen wir den Code irgendwie lokal bei uns zur Verfügung haben. Eine zweite Minute wäre natürlich, den Quellcode von React runterzuladen. Könnten wir mal...\n",
      "📝 segment_0085.wav: ist heutzutage aber eher altmodisch.\n",
      "📝 segment_0086.wav: wenn wir zum Beispiel eine neue Version von React installieren wollen, müssten wir wieder auf die React-Webseite den Code herunterladen. Also das ist ein Vorgehen, welches eher heutzutage nicht mehr zu empfehlen ist. Da gibt es höhere Methoden. Die eine, die wir jetzt in der\n",
      "📝 segment_0087.wav: ist die Nutzung einer sogenannten CDN-URL. CDN steht für Content Delivery Network. Das ist letztendlich einfach eine Website, auf der React uns den Quellkurs macht.\n",
      "📝 segment_0088.wav: schon einmal hochgeladen hat und den wir über die URL ganz einfach in unserer Index-HTML einbinden können. Und das ist ideal für schnelle Tests oder auch für Lernprojekte, so wie dieses Jahr hier ein Lernprojekt ist. Und dementsprechend werden wir auch heute\n",
      "📝 segment_0089.wav: diese Variante der Installation von React zurückgreifen. Die vierte Variante, die es auch noch gibt, ist natürlich\n",
      "📝 segment_0090.wav: die Installation mit NPM. Den React gibt es auch auf NPM. Das zeige ich euch an dieser Stelle.\n",
      "📝 segment_0091.wav: nicht. Rack wurde auch auf NPM hochgeladen. Es ist allerdings so, dass die Installation über NPM beziehungsweise danach die Einbindung in eure Website nicht ganz so leicht ist.\n",
      "📝 segment_0092.wav: von da angeht. Da braucht es dann doch das ein oder andere Tool, was die Sache initial sehr komplex macht. Das rentiert sich bei größeren Applikationen aber absolut, denn dieser initial komplexe Aufwand wird dann amortisiert.\n",
      "📝 segment_0093.wav: über viel Arbeit, die uns diese Variante später erspart. Die Installation von Reakt mit NPM werden wir in einer späteren Folge dann auch noch vornehmen, spätestens im zweiten Teil dieser Videoserie, wo sich ja alles um das Tooling drehen wird.\n",
      "📝 segment_0094.wav: Für heute, wie gesagt, nutzen wir auch\n",
      "📝 segment_0095.wav: den CDL URL Link. Das Ganze sieht dann so aus.\n",
      "📝 segment_0096.wav: dass wir in unserer index.html diese zwei Script Tags einführen. Und damit ist...\n",
      "📝 segment_0097.wav: dann auf unserer Seite schon verfügbar. Diese zwei Script Text findet ihr ebenfalls auf der react.js.org auf der offiziellen Seite unter CDN Links. Ihr werdet ihr sehen, das ist zwei unterschiedliche Varianten.\n",
      "📝 segment_0098.wav: die Projekt einzublenden, einmal im Development Modus und einmal im Production Modus. Der Unterschied ist ganz einfach, dass der Development Modus einige bessere Fehlermeldungen zur Verfügung stellt und einige Tools uns zur Verfügung stellt, die das entwickeln von\n",
      "📝 segment_0099.wav: React leichter machen, die aber gleichzeitig diese JavaScript-Dateien sehr aufplänen und sehr groß machen. Im produktiven Einsatz von React wollen wir natürlich so wenig wie möglich Code auf der Seite, weil der ja auch heruntergeladen werden muss. Dementsprechend hier diese Unterscheidungen. Da wir jetzt aber noch\n",
      "📝 segment_0100.wav: weit weg sind von einem produktiven Einsatz, beschränken wir uns heute auf die Development Sources, die ich hier einfach schon mal kopiere. Wenn wir dann nachher die Reaktion von der Reaktion von der Reaktion von der Reaktion\n",
      "📝 segment_0101.wav: in unserem Projekt eingebunden haben, wollen wir...\n",
      "📝 segment_0102.wav: natürlich auch verwenden. Und den ersten Code oder das erste Code, das wir jetzt in der ersten Runde haben, das ist der Code, der wir jetzt in der ersten Runde haben. Und das ist der Code, der wir jetzt in der ersten Runde haben. Und das ist der Code, der wir jetzt in der ersten Runde haben. Und das ist der Code, der wir jetzt in der ersten Runde haben. Und das ist der Code, der wir jetzt in der ersten Runde haben. Und das ist der Code,\n",
      "📝 segment_0103.wav: Der erste, den ersten Block mit React, den wir verwenden werden, ist eben, wie vorher angekündigt, schon React Element. React Element oder ein React Element erstellen wir über diesen Funktionsauffruch React CreateElement und der besteht aus drei Parametern.\n",
      "📝 segment_0104.wav: Der erste Parameter gibt das HTML-Tag an, das wir generieren wollen. In diesem Fall zum Beispiel ein P-Tag.\n",
      "📝 segment_0105.wav: Der zweite Parameter gibt an, welche Attribute wir diesem HTML-Tag mitgeben wollen. In diesem Fall jetzt eine IT. Und der dritte Parameter gibt an, welchen Inhalt wir in dieses HTML-Tag reinstellen.\n",
      "📝 segment_0106.wav: in dem Fall hier jetzt myContent. Dieser Funktionsaufruf macht letztendlich nichts anderes als ein simples JavaScript-Objekt zu erzeugen. Dieses JavaScript-Objekt wird aber von React verstanden und kann dann von React\n",
      "📝 segment_0107.wav: wiederum in den Virtual DOM von React implementiert werden oder eigentlich.\n",
      "📝 segment_0108.wav: werden. Sobald es im Virtual Dom eingebunden ist, wir erinnern uns, React synchronisiert den\n",
      "📝 segment_0109.wav: Virtual Dom, dann mit dem richtigen Dom, wird eben dieses Element zu einem realen Dom-Objekt und dementsprechend dem Browser dargestellt. Man kann also sagen, dass ein React-Element ein reales Dom ist.\n",
      "📝 segment_0110.wav: Objekt repräsentiert.\n",
      "📝 segment_0111.wav: Visualisierung noch einmal anschauen. Haben wir nun also neben dem VirtualDOM für React in unseren JavaScript-Dateien diesen Funktionsaufruf ReactCreateElement, welcher dann eben hier im VirtualDOM als einzelnen Element eingebunden wird, dann mit dem DOM Synchron.\n",
      "📝 segment_0112.wav: und nachher in unserem Browser dargestellt. Dieser Visualisierung habe ich ebenfalls npm hinzugefügt, welches eben über die Package Chasing, die wir gerade schon gesehen haben, initialisiert und installiert wird. Und wir haben npx kennengelernt.\n",
      "📝 segment_0113.wav: was uns den Wert selber startet.\n",
      "📝 segment_0114.wav: wollen wir das Ganze noch einmal eben umsetzen. Wir kopieren nochmal kurz die Sources.\n",
      "📝 segment_0115.wav: Die brauchen wir jetzt als allererstes. Gehen zurück in unser V-Shirt.\n",
      "📝 segment_0116.wav: Studio und fügen nun React ganz einfach am Ende des Bodytags ein. An sich war es das schon. Jetzt haben wir React auf unserer Seite.\n",
      "📝 segment_0117.wav: Wir tun aber natürlich noch nichts damit. Um nur etwas damit zu tun, brauchen wir noch etwas eigenes JavaScript, das wir einbetten. Dementsprechend fügen wir nun erstmal hier noch ein zweites oder ein drittes Script Tag hinzu. Das bei uns auch.\n",
      "📝 segment_0118.wav: auf sourceapp.js zeigen wird. Dieser Datei legen wir dann noch an. Erstmal ein Ordner source. Das ist einfach ein gängiges Vorgehen.\n",
      "📝 segment_0119.wav: eben für Source, in dem alle Source-Dateien eines Projektes abgelegt werden. Dort legen wir dann die Datei an. App.js. Bevor wir nun JavaScript schreiben, bereiten wir in der index.html\n",
      "📝 segment_0120.wav: noch eine weitere Sache vor. Wir erinnern uns vielleicht das letzte Mal an die React DOM Render\n",
      "📝 segment_0121.wav: Funktion, der wir zum einen mitgeben, eine React-Komponente, die wir gerendert haben wollen, zum anderen aber auch angeben müssen, wohin.\n",
      "📝 segment_0122.wav: in unserem HTML wir diese Komponente gewinnert haben wollen. Und dieses wohin erstellen wir jetzt hier. Wir machen uns ein einfaches div und geben dem eine ID anhand der wir es dann später identifizieren können und das nennen wir...\n",
      "📝 segment_0123.wav: dann einfach react in das App.\n",
      "📝 segment_0124.wav: kurz auf die Seite schauen. Es hat sich nichts verändert. Alles beim alten, weil wir noch kein Reakt-Element generiert haben, das wir hier einbinden. Das tun wir jetzt. Zuerst generieren wir uns\n",
      "📝 segment_0125.wav: also ein React Element. Das speichern wir in eine Variable, die wir jetzt einfach mal Element nennen, nutzen und eben React.\n",
      "📝 segment_0126.wav: createElement. Reakt, design included.\n",
      "📝 segment_0127.wav: Variable, die uns jetzt eben zur Verfügung steht, weil wir ja hier diese über dieses Script eingebunden haben. Das Script macht letztendlich nichts anderes als die Reakt-Sourcen unter dieser Variablen zur Verfügung.\n",
      "📝 segment_0128.wav: zu stellen und so auch die CreateElement-Methode. Als ersten Parameter eben das Tag, in dem Fall bleiben wir mal beim Ptag. Als zweitem Parameter\n",
      "📝 segment_0129.wav: die Attribute. Das lassen wir erstmal leer. Und als dritten Parameter den Content. Wir schreiben jetzt einfach rein.\n",
      "📝 segment_0130.wav: Das ist mein erster Projekt.\n",
      "📝 segment_0131.wav: erstes React Element. Richtiger. Wie nur angesprochen, React Create Element generiert erst mal nur ein simples JavaScript-Objekt. Mit diesem Objekt müssen wir jetzt noch etwas tun.\n",
      "📝 segment_0132.wav: müssen wir sagen, wohin es uns dieses JavaScript objektiv\n",
      "📝 segment_0133.wav: oder dieses React Element nachher im Browser rendern soll.\n",
      "📝 segment_0134.wav: und dazu nutzen wir React-DOM. Das ist ebenfalls eine globale Variable, die uns zur Verfügung steht, weil wir hier dieses zweite Skript eingebunden haben für React-DOM. Das liefert uns eben die Renderfunktion.\n",
      "📝 segment_0135.wav: und die wir noch zuerst unser Element reingeben. Und nun sagen müssen, wohin wir das gewendet haben wollen.\n",
      "📝 segment_0136.wav: uns ja vorher das div angelegt und eine id verpasst und das können wir hier\n",
      "📝 segment_0137.wav: nun mit einem Selektor herausfinden oder herausfiltern, indem wir sagen document getElementById und hier die ID, die wir\n",
      "📝 segment_0138.wav: vorher vergeben haben, in dem Fall React App. Kopieren und einfügen. Wenn wir das Ganze speichern und auf die Website gehen, dann sehen wir, juhu, wir haben unsere\n",
      "📝 segment_0139.wav: erste Projekt-Element auf der\n",
      "📝 segment_0140.wav: Website gerendert. Wir haben zum allerersten Mal React eingesetzt um unseren\n",
      "📝 segment_0141.wav: Daumen zu manipulieren. Das ist natürlich jetzt noch etwas statisch, aber ist doch überall schon mal ein toller\n",
      "📝 segment_0142.wav: erster Schritt. Jetzt werdet ihr euch fragen, ich habe das letzte mal erzählt von deklarativen Programmieren und von JSX, dass es uns erlaubt HTML in JavaScript-Dateien zu schreiben. Ihr würdet nun erwarten, dass wir eigentlich...\n",
      "📝 segment_0143.wav: das ganze nicht hier mit dem Reactor Element Aufruf machen, sondern eher so\n",
      "📝 segment_0144.wav: schreiben können, wie so. Also ein HTML Element mit der IID direkt in der IID.\n",
      "📝 segment_0145.wav: JavaScript-Datei.\n",
      "📝 segment_0146.wav: werden wir einen Fehler bekommen. Wenn wir zurück navigieren in den Browser, sehen wir zum einen, dass unsere Elemente\n",
      "📝 segment_0147.wav: nicht mehr gerendert wurde. Um herauszufinden, was hier gerade schiefgelaufen ist, können wir die Entwicklertools von Chrome oder auch von jedem anderen Browser, jeder Browser bringt Entwicklertools mit, uns zur Hand nehmen. Das können wir entweder über die Taste F12 machen oder …\n",
      "📝 segment_0148.wav: dem wir rechtsklick untersuchen machen.\n",
      "📝 segment_0149.wav: untersuchen sehen wir dann unseren aktuellen DOM oder unser HTML, das wir auch hier durchnavigieren können. Unser Title, unser MetaCharSet, eben der Buddy.\n",
      "📝 segment_0150.wav: und dann mal hinzuklicken. So, perfekt. Und wir haben auch die Konsole.\n",
      "📝 segment_0151.wav: die uns Fehler ausspuckt. Und in diesem Fall sehen wir jetzt\n",
      "📝 segment_0152.wav: Wir haben einen Sündungsfehler. Ein unerwartetes Zeichen.\n",
      "📝 segment_0153.wav: Unexpected Token, eine geöffnete Klammer. Und das ist genau dieses Zeichen. Blick daran, dass ein Browser heutzutage zumindest noch\n",
      "📝 segment_0154.wav: nicht JSX versteht. Ein Browser versteht nur natives JavaScript und das hier ist nun mal kein natives JavaScript. Dementsprechend kann der Browser\n",
      "📝 segment_0155.wav: diesen Coach-Schnippel einfach auch nicht verstehen. Und wir müssen erst etwas tun.\n",
      "📝 segment_0156.wav: damit er das kann. Wir müssen nämlich diesen Code Snippet zurück umwandeln in ganz normales JavaScript. Und an dieser Stelle schon ein kleiner Hint. React-Create-Element ist ganz normales JavaScript. Das haben wir gerade gesehen, dass das funktioniert. Und das nutze ich jetzt.\n",
      "📝 segment_0157.wav: ermöglichen und um diese Übersetzung vorzunehmen, das müssen wir natürlich nicht händisch machen, das wäre sehr aufwendig, sondern da gibt es Tools. Und eines dieser Tools...\n",
      "📝 segment_0158.wav: Wir gehen zurück zur Theorie, Test Babel.\n",
      "📝 segment_0159.wav: eben so eine Art Helferin oder eine Übersetzerin, die uns Features und Funktionen, sowie GSX, zurück übersetzt in natives JavaScript, das der Browser versteht. Babel besteht im Wesentlichen aus drei Kernkomponenten.\n",
      "📝 segment_0160.wav: die wir heute einsetzen werden. Das ist einmal der Core. Das ist die gesamte Übersetzungslogik. Das Command-Win-Interface oder kurz CLI, das lässt\n",
      "📝 segment_0161.wav: uns mit Babel kommunizieren und sprechen und Babel mitteilen, was wir eigentlich übersetzt haben wollen. Und es gibt Presets. Presets könnt ihr euch vorstellen als Wörterbücher, die wir Babel mitgeben, um Babel zu ermöglichen, beispielsweise JSX in Normal.\n",
      "📝 segment_0162.wav: JavaScript zu übersetzen. Und wir setzen heute Preset React ein.\n",
      "📝 segment_0163.wav: React ist eben genau dieses Wörterbuch, das den Einsatz von JSX in unseren Dateien erlaubt. Und Babel wird dieses JSX dann umwandeln.\n",
      "📝 segment_0164.wav: ganz normales JavaScript.\n",
      "📝 segment_0165.wav: schauen. Aktuell standen wir hier mit JavaScript.\n",
      "📝 segment_0166.wav: von Create Element ausgeführt. Das hat funktioniert, haben jetzt aber JSX mit reingebracht.\n",
      "📝 segment_0167.wav: gebracht. Das hat nicht mehr funktioniert. JSX müssen wir also nun erst durch Babel schleifen.\n",
      "📝 segment_0168.wav: normales JavaScript umzuwandeln, das dann wiederum von React bzw. von unseren Browsern auch verstanden werden kann. Und an dieser Stelle wird es vielleicht schon langsam bewusst. Babel macht nichts anderes als aus diesen JSXs.\n",
      "📝 segment_0169.wav: Snippets oder aus den HTML-Teilen in JavaScript, die wir in JSX schreiben. react.create-elements.\n",
      "📝 segment_0170.wav: Funktionsaufrufe zu machen. Das ist die ganze Magie, die ...\n",
      "📝 segment_0171.wav: dahinter steckt und das zeige ich euch auch gleich hands-on. Aber zuerst, wie installieren wir Babel? Dazu nutzen wir nun eben NPM und wir werden den Babel Core\n",
      "📝 segment_0172.wav: die Babel CLI und das Preset React in unserem Projekt installieren.\n",
      "📝 segment_0173.wav: Und das machen wir jetzt.\n",
      "📝 segment_0174.wav: also in die Command Line. Wir beenden mal kurz unseren Web Server an dieser Stelle und führen nun das Command aus. npm install add fabel core add fabel cli\n",
      "📝 segment_0175.wav: und add-bobble-reset-react. Wir fügen hier noch einen kleinen weiteren Parameter hinzu, nämlich \"-save-def\". Warum wir das tun, erkläre ich dann gleich.\n",
      "📝 segment_0176.wav: estava\n",
      "📝 segment_0177.wav: weil er die ganzen Pakete natürlich erst runterladen muss. Jetzt seht ihr hier ein Error, das passiert auf Mac. Nicht wundern, wenn ihr diesen Error seht und auch keine Sorge, das spielt für uns erstmal keine Rolle. Ein paar Features von Babel werden wegen diesem Error...\n",
      "📝 segment_0178.wav: nicht funktionieren. Das sind aber keine Features, die wir jetzt gerade benötigen. Von dem her können wir diesen Error einfach getrost ignorieren. Die Installation ist abgeschlossen.\n",
      "📝 segment_0179.wav: gehen wir zurück in Visual Studio Code. Schauen wir mal kurz, hier hat sich etwas verändert. Zum einen wurden in unserer Package Chasen ein neues Feld hinzugefügt, nämlich diese Dev-Dependencies. Das ist das, was ich mit dem Befehl \"--save dev-\"\n",
      "📝 segment_0180.wav: veranlasst habe und das schreibt letztendlich einfach alle Abhängigkeiten unseres Projekts oder alle Entwicklungsabhängigkeiten.\n",
      "📝 segment_0181.wav: diese Package chasen. Ich will jetzt nicht zu sehr ins Detail gehen, weil das ist ja ein Kurs über React und nicht über NPM.\n",
      "📝 segment_0182.wav: dass ihr versteht warum ich diesen Fehler angegeben habe. Es ist auch eine Package LogJSON generiert worden, das ist sozusagen ein Logbuch aller derer Pakete, die wir installiert haben mit genauen Funktionen und zu guter Letzt wurde hier Node Modules angelegt, das ist der\n",
      "📝 segment_0183.wav: in denen die Pakete, die wir installiert haben, tatsächlich heruntergeladen wurden. Wenn wir das mal kurz aufmachen.\n",
      "📝 segment_0184.wav: sehen wir hier natürlich deutlich mehr als wir installiert haben. Das liegt einfach dran, dass Babel selbst ja auch Abhängigkeiten hat, die es wieder\n",
      "📝 segment_0185.wav: herum über eine Package JSON definiert und alle diese Abhängigkeiten installiert.\n",
      "📝 segment_0186.wav: oder npm für uns dann gleich mit, dass wir das nicht händisch machen müssen. Aber wir sehen auch, add-babel-cli wurde installiert, add-babel-core wurde installiert.\n",
      "📝 segment_0187.wav: installiert.\n",
      "📝 segment_0188.wav: Und weiter unten, at Babel Presaved Reakt, ist dann auch in unserem Projekt vorhanden. Nun müssen wir Babel noch entsprechend ein wenig konfigurieren.\n",
      "📝 segment_0189.wav: beziehungsweise auch ausführen. Denn aktuell wüsste Babi ja noch nicht, was es tun soll.\n",
      "📝 segment_0190.wav: und Babel weiß aktuell auch noch nicht, welche Wörterbücher es einsetzen soll. Fangen wir mit dem Wörterbuch an. Wir können Babel ganz einfach konfigurieren, indem wir nochmal eine neue Datei anlegen, die sich pro ...\n",
      "📝 segment_0191.wav: Punkt.\n",
      "📝 segment_0192.wav: In dieser Datei können wir valides JSON schreiben, also das ist eigentlich nur eine JSON Datei, auch wenn sie nicht auf JSON endet. Wir können dort ein Objekt anlegen und das Feld Presets befüllen.\n",
      "📝 segment_0193.wav: und dort nun in einem Array alle die Presets reinschreiben, die bar...\n",
      "📝 segment_0194.wav: für uns verwenden. Also sprich alle diese Wörterbücher, die wir übersetzen wollen. In unserem Fall ist das nur eines, nämlich Babel.\n",
      "📝 segment_0195.wav: preset wirkt. Das ist der erste Schritt. Im zweiten Schritt müssen wir nun aus dieser App.js eine App.js\n",
      "📝 segment_0196.wav: Datei machen. Denn wir haben hier ja tatsächlich nicht mehr valides JavaScript stehen, deswegen ist das auch keine JavaScript Datei mehr, sondern es ist jetzt eine JSX Datei, weil wir hier JSX eingefügt haben. Und nun müssen wir Babel diese Datei...\n",
      "📝 segment_0197.wav: für uns übersetzen lassen. Das können wir nun eben mit barb's CLI über die command line tun.\n",
      "📝 segment_0198.wav: Und zwei Möglichkeiten. Wir könnten hier auch wieder NPX einsetzen, um quasi Babel direkt auszuführen. Wir haben aber die Babel CLI ja auch bei uns installiert.\n",
      "📝 segment_0199.wav: und das ganze nämlich in Node Modules, dem sogenannten Bin oder Binary Folder, gibt es den Befehl Babel. Dieser Befehl\n",
      "📝 segment_0200.wav: erwartet drei Parameter. Zum einen das Surs-Verzeichnis oder das Verzeichnis, das Babel für uns übersetzen soll. In unserem Fall ist das tatsächlich Surs. Es erwartet den Parameter M.\n",
      "📝 segment_0201.wav: Das ist die Stelle, wo Babel die kombinierten oder die übersetzten Dateien hinschreiben soll. Und das machen wir bei uns jetzt einfach mal in ein Verzeichnis, dass wir\n",
      "📝 segment_0202.wav: Lippnen. Wenn wir mit diesen Befehlungen ausführen,\n",
      "📝 segment_0203.wav: Quittiert uns Babel das mit einer erfolgreichen Meldung, dass es uns eine Datei erfolgreich kompiliert hat oder übersetzt hat. Wenn wir zurück ins Projektverzeichnis springen, sehen wir auch, dass der Lipfolder angelegt wurde und hier.\n",
      "📝 segment_0204.wav: entsprechend analog zu unserer App.jsx eine App.js-Datei angelegt wurde. Und die können wir uns auch anschauen. Und siehe da. Aus unserem.jsx ist nichts anderes geworden als ein React Create Element auf\n",
      "📝 segment_0205.wav: der relativ oder nicht noch relativ, sondern ziemlich gleich aussieht, wie das, was wir davor haben.\n",
      "📝 segment_0206.wav: hindisch eingegeben haben. Das ist tatsächlich die gesamte Magie hinter GSX und Babel. Es macht nichts anderes als die Teile die HTML...\n",
      "📝 segment_0207.wav: und unserem JSExit in ein React.CreateElement zu übersetzen. Nun müssen wir, damit das auch funktioniert, noch eine kleine Änderung in unserer Index-HTML vornehmen, weil wir jetzt nicht mehr die App.js aus unserem Source auswählen.\n",
      "📝 segment_0208.wav: ausliefern oder die App JSX, sondern wir müssen ja die übersetzte Variante\n",
      "📝 segment_0209.wav: unserer App ausliefern. Dementsprechend ändern wir das hier einfach auf lib. Und wenn wir nun nochmal einen LAP Server starten.\n",
      "📝 segment_0210.wav: und zurück auf unsere Webseite.\n",
      "📝 segment_0211.wav: Zeit navigieren. Sehen wir, wir haben ein erstes Rigged Element.\n",
      "📝 segment_0212.wav: Weil wir hier noch das alte Element auch eingebunden haben, wir wollen jetzt aber eigentlich hier das die erste ChessX-Komponente einbinden. Dementsprechend müssen wir das hier\n",
      "📝 segment_0213.wav: Wir wollen nun MyJSX Element rendern. Wir müssen das ganze jetzt natürlich von Babel nochmal neu übersetzen lassen. Wenn wir jetzt den Web-Server starten...\n",
      "📝 segment_0214.wav: sollten wir tatsächlich sehen, dass wir unsere ersten JSX-Komponente erfolgreich im Browser gewendet haben. Das ist super!\n",
      "📝 segment_0215.wav: zum Abschluss kommen, möchte ich euch noch einen kleinen Tipp mitgeben, denn diesen Befehl, den wir hier gerade gesehen haben, NodeModules.bin.barbisource ist schwer zu merken und ist auch nicht sonderlich schön einzutippen. Da können wir uns mit NPL\n",
      "📝 segment_0216.wav: und mit npm scripts ein wenig Abfehlung verschaffen. Scripts erlaubt uns es nämlich Scripte unter einem sogenannten alias oder einem anderen Namen vorzudefinieren. Wenn wir jetzt also hier sowas wie compile schreiben und dort\n",
      "📝 segment_0217.wav: den Befehl.\n",
      "📝 segment_0218.wav: minus minus out your blip, Gefolgt von einem Komma reinschreiben, können wir diesen sehr aufwändigen Befehl deutlich\n",
      "📝 segment_0219.wav: leichter in unserer Command Line ausführen. Ganz kurz, wir können uns hier das Node-Module Spin sparen.\n",
      "📝 segment_0220.wav: weil die Scripts von npm per Default dieses Binary-Verzeichnis einbinden. Das heißt, hier können wir auf diesen ganzen vorherigen Pfad verzichten und einfach Babel direkt ausführen. Und nun können wir einfach über den Befehl...\n",
      "📝 segment_0221.wav: in unserem aktuellen Verzeichnis npm run, jedes Script, das wir definiert haben, ausführen. In unserem Fall nur compile. Wie wir sehen, wurde Babel wieder ausgeführt. Um uns, unsere ...\n",
      "📝 segment_0222.wav: oder JSX-Dateien zu übersetzen. Letztendlich kann hier in ...\n",
      "📝 segment_0223.wav: scripts jedes valide CLI-Commandos.\n",
      "📝 segment_0224.wav: eingefügt werden. Und wir können so die für unser Projekt relevanten C&I Command sehr sehr einfach und sehr sehr überstiftig...\n",
      "📝 segment_0225.wav: in der Package schäfen. Das ist ein kleiner Trick, der in vielen Projekten auch sehr...\n",
      "📝 segment_0226.wav: eingesetzt wird. Das können wir zum Beispiel als letztes noch erweitern, indem wir hier npx server eintragen und wir uns somit nicht mehr npx server eintippen müssen, sondern nun um unseren Web Server zu starten.\n",
      "📝 segment_0227.wav: und die Website auszuliefern, npm run start eingeben können. Und nun ist unser Webserver wieder verfügbar. Und das war es auch schon.\n",
      "📝 segment_0228.wav: heutigen Folge. Nochmal ein kurzes Review. Was haben wir gemacht? Wir haben das lokale Setup mit Visual Studio Code und NPM vorbereitet. Ich habe einen ersten Einblick in die Toolkit.\n",
      "📝 segment_0229.wav: NPM, NPX und Babel gegeben und wir haben diese auch schon live eingesetzt. Wir haben React eingebunden mit der Variante CDN oder Content Delivery Network.\n",
      "📝 segment_0230.wav: und wir haben mit React Element und JSX eine erste Hello World Applikation von React implementiert. Da haben wir schon einen großen Schritt gemacht. Das nächste Mal wird es ein\n",
      "📝 segment_0231.wav: noch spannender. Da werden wir nämlich React Components vorstellen und einsetzen und mit den React Components die Renderfunktion, Props und dann noch ein paar\n",
      "📝 segment_0232.wav: Besonderheiten von GSX kennenlernen. An dieser Stelle bedanke ich mich recht herzlich, dass ihr dieses Video angesehen habt. Ich hoffe, ihr konntet etwas lernen. Bei Fragen, Feedback oder sonstigen Wünschen und Anregungen meldet euch gerne an.\n",
      "📝 segment_0233.wav: bei uns über diese Kanäle hello.atthenativefab.io per E-Mail oder auch auf Twitter und GitHub. Und ich wünsche euch jetzt noch einen schönen Tag und bis zur nächsten!\n",
      "📝 segment_0234.wav: nächsten Folge.\n",
      "📝 segment_0235.wav: Tschüss!\n",
      "✅ Metadata saved to: metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import csv\n",
    "\n",
    "def transcribe_and_generate_metadata(audio_folder, metadata_file=\"metadata.csv\", model_size=\"medium\"):\n",
    "    # Initialize Whisper model\n",
    "    model = whisper.load_model(model_size, download_root=\"/home/ahmet/.cache/whisper\", device=\"cuda\")\n",
    "\n",
    "    # Prepare CSV file\n",
    "    with open(metadata_file, mode='w', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter='|')\n",
    "        \n",
    "        # Process each WAV file\n",
    "        for wav_file in sorted(os.listdir(audio_folder)):\n",
    "            if wav_file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(audio_folder, wav_file)\n",
    "\n",
    "                # Transcribe audio\n",
    "                result = model.transcribe(file_path, language=\"de\")  # Set language accordingly\n",
    "                transcript = result.get(\"text\", \"\").strip()\n",
    "\n",
    "                # Add entry to CSV\n",
    "                writer.writerow([wav_file, transcript, transcript])\n",
    "                print(f\"📝 {wav_file}: {transcript}\")\n",
    "\n",
    "    print(f\"✅ Metadata saved to: {metadata_file}\")\n",
    "\n",
    "# Run transcription\n",
    "audio_folder = \"segmented_audio\"\n",
    "transcribe_and_generate_metadata(audio_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixed metadata.csv! Saved as metadata_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Paths\n",
    "input_csv = \"audio_dataset_2/metadata.csv\"\n",
    "output_csv = \"audio_dataset_2/metadata_fixed.csv\"\n",
    "\n",
    "# Fix .wav extensions\n",
    "with open(input_csv, \"r\", encoding=\"utf-8\") as infile, open(output_csv, \"w\", encoding=\"utf-8\", newline=\"\") as outfile:\n",
    "    reader = csv.reader(infile, delimiter=\"|\")\n",
    "    writer = csv.writer(outfile, delimiter=\"|\")\n",
    "\n",
    "    for row in reader:\n",
    "        # Remove '.wav' from first column if it exists\n",
    "        filename = row[0].replace(\".wav\", \"\")\n",
    "        writer.writerow([filename, row[1], row[2]])\n",
    "\n",
    "print(\"✅ Fixed metadata.csv! Saved as metadata_fixed.csv\")\n",
    "\n",
    "# Optional: Replace the old file with the new one\n",
    "import os\n",
    "os.replace(output_csv, input_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
