{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source /workspace/tts_env/bin/activate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmet/anaconda3/envs/tts_env/lib/python3.10/site-packages/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
      "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmet/anaconda3/envs/tts_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmet/anaconda3/envs/tts_env/lib/python3.10/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "/home/ahmet/anaconda3/envs/tts_env/lib/python3.10/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "tts_2 = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def resample_wav(input_wav, output_wav, target_sr=44100):\n",
    "    \"\"\"\n",
    "    Resample a WAV file to the target sample rate.\n",
    "\n",
    "    :param input_wav: Path to the input WAV file (e.g., \"output_22k.wav\")\n",
    "    :param output_wav: Path to the resampled output WAV file (e.g., \"output_44k.wav\")\n",
    "    :param target_sr: Target sample rate (default: 44100Hz)\n",
    "    \"\"\"\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(input_wav, sr=None)  # Load with original SR\n",
    "\n",
    "    # Resample audio\n",
    "    resampled_audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "\n",
    "    # Save the resampled audio\n",
    "    \n",
    "    sf.write(output_wav, resampled_audio, target_sr)\n",
    "\n",
    "    print(f\"âœ… Resampled {input_wav} from {sr}Hz to {target_sr}Hz â†’ Saved as {output_wav}\")\n",
    "\n",
    "# Example usage after cloning:\n",
    "# Assuming cloned output is saved as \"output_22k.wav\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Hello everyone.', 'Today I will teach you how to print from the computer.', 'Please turn on your computers']\n",
      " > Processing time: 1.5583691596984863\n",
      " > Real-time factor: 0.19447862883360287\n",
      "âœ… Resampled org_en.wav from 24000Hz to 44100Hz â†’ Saved as org_en_44_3.wav\n"
     ]
    }
   ],
   "source": [
    "REFERENCE_AUDIO= \"cropped_0_16.wav\"\n",
    "sentence = \"Hello everyone. Today I will teach you how to print from the computer. Please turn on your computers\"\n",
    "\n",
    "tts_2.tts_to_file(text=sentence, speaker_wav=REFERENCE_AUDIO, language=\"en\", file_path=\"org_en.wav\")\n",
    "resample_wav(\"org_en.wav\", \"org_en_44_3.wav\", target_sr=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['Herkese merhaba bugÃ¼n sizlere bilgisayardan nasÄ±l dosya yazdÄ±rÄ±lacaÄŸÄ±nÄ± gÃ¶stereceÄŸim.', 'lÃ¼tfen bilgisayarlarÄ±nÄ±zÄ± aÃ§Ä±n.']\n",
      " > Processing time: 1.546891689300537\n",
      " > Real-time factor: 0.1903062050809947\n",
      "âœ… Resampled FT_en_new.wav from 22050Hz to 44100Hz â†’ Saved as FT_tr_ipa_44.wav\n",
      "ğŸ‰ Fine-tuned voice generated! Check output.wav\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "import torch\n",
    "import os\n",
    "torch.cuda.empty_cache()  # âœ… Clears GPU memory cache\n",
    "\n",
    "# âœ… Define paths\n",
    "MODEL_PATH = os.path.join(os.getcwd(),\"fine_tuning_output_3/XTTS_v2_FT_ipa\")\n",
    "CONFIG_PATH = os.path.join(os.getcwd(),\"fine_tuning_output_3/XTTS_v2_FT_ipa/config.json\")\n",
    "REFERENCE_AUDIO= os.path.join(os.getcwd(),\"cropped_0_16.wav\")\n",
    "# âœ… Load fine-tuned XTTS\n",
    "tts = TTS(model_path=MODEL_PATH, config_path=CONFIG_PATH).to(\"cuda\")\n",
    "\n",
    "# âœ… Define test sentence\n",
    "sentence = \"Herkese merhaba bugÃ¼n sizlere bilgisayardan nasÄ±l dosya yazdÄ±rÄ±lacaÄŸÄ±nÄ± gÃ¶stereceÄŸim. lÃ¼tfen bilgisayarlarÄ±nÄ±zÄ± aÃ§Ä±n.\"\n",
    "\n",
    "# âœ… Generate speech\n",
    "tts.tts_to_file(text=sentence, speaker_wav=REFERENCE_AUDIO, language=\"tr\", file_path=\"FT_en_new.wav\")\n",
    "resample_wav(\"FT_en_new.wav\", \"FT_tr_ipa_44.wav\", target_sr=44100)\n",
    "print(\"ğŸ‰ Fine-tuned voice generated! Check output.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Cropped 0-16s â†’ cropped_0_16.wav\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def crop_audio(input_path, output_path, start_sec=0, end_sec=16):\n",
    "    \"\"\"Crop audio between start and end seconds.\"\"\"\n",
    "    audio = AudioSegment.from_file(input_path)\n",
    "    cropped = audio[start_sec * 1000:end_sec * 1000]  # pydub works with milliseconds\n",
    "    cropped.export(output_path, format=\"wav\")\n",
    "    print(f\"ğŸ¯ Cropped {start_sec}-{end_sec}s â†’ {output_path}\")\n",
    "\n",
    "# Usage\n",
    "crop_audio(\"org.mp4\", \"cropped_0_16.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Š Stabilized: FT_en_new_44_stable.wav\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Re-normalize output audio with stable amplitude\n",
    "def stabilize_volume(input_wav, output_wav):\n",
    "    y, sr = librosa.load(input_wav, sr=None)\n",
    "    y_normalized = librosa.util.normalize(y)  # Normalize amplitude\n",
    "    sf.write(output_wav, y_normalized, sr)\n",
    "    print(f\"ğŸ”Š Stabilized: {output_wav}\")\n",
    "\n",
    "stabilize_volume(\"FT_en_new_44.wav\", \"FT_en_new_44_stable.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ahmet/my_projects/realtime_translator_V2_updated/model_train'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ahmet ahmet 353K Feb 11 20:59 ./xtts_checkpoints/vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./xtts_checkpoints/vocab.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "def get_wav_sample_rate(wav_path):\n",
    "    \"\"\"Returns the sample rate (Hz) of a given WAV file.\"\"\"\n",
    "    try:\n",
    "        sample_rate = librosa.get_samplerate(wav_path)\n",
    "        return sample_rate\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Example usage (update with your actual file path)\n",
    "wav_file_path = \"FT_en_new_44.wav\"  # Replace with your actual file\n",
    "sample_rate = get_wav_sample_rate(wav_file_path)\n",
    "sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasÉªlsÉªn \n"
     ]
    }
   ],
   "source": [
    "from phonemizer import phonemize\n",
    "\n",
    "word = \"nasilsin\"\n",
    "ipa = phonemize(word, language=\"tr\", backend=\"espeak\")\n",
    "print(ipa)  # Output: /teÊƒeËˆkÊ°yÉ¾/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Turkish          IPA\n",
      "      seni       /seni/\n",
      "gÃ¶rdÃ¼gÃ¼mde /É¡Ã¸É¾dyÉ¡ymde/\n",
      " gercekten /É¡eÉ¾dÊ’ekten/\n",
      "     mutlu      /mutlu/\n",
      " oluyorum.  /olujoÉ¾um./\n",
      "  inmazsan   /inmazsan/\n",
      "       sor        /soÉ¾/\n"
     ]
    }
   ],
   "source": [
    "# âœ… Define Turkish â†’ IPA Mapping\n",
    "IPA_DICT = {\n",
    "    \"a\": \"a\", \"b\": \"b\", \"c\": \"dÊ’\", \"Ã§\": \"tÊƒ\", \"d\": \"d\", \"e\": \"e\", \"f\": \"f\",\n",
    "    \"g\": \"É¡\", \"ÄŸ\": \"É£\", \"h\": \"h\", \"Ä±\": \"É¯\", \"i\": \"i\", \"j\": \"Ê’\", \"k\": \"k\",\n",
    "    \"l\": \"l\", \"m\": \"m\", \"n\": \"n\", \"o\": \"o\", \"Ã¶\": \"Ã¸\", \"p\": \"p\", \"r\": \"É¾\",\n",
    "    \"s\": \"s\", \"ÅŸ\": \"Êƒ\", \"t\": \"t\", \"u\": \"u\", \"Ã¼\": \"y\", \"v\": \"v\", \"y\": \"j\", \"z\": \"z\",\n",
    "    # Special cases for better pronunciation\n",
    "    \"ev\": \"ev\", \"an\": \"É‘n\", \"en\": \"en\", \"at\": \"É‘t\", \"et\": \"et\", \n",
    "    \"il\": \"il\", \"ol\": \"ol\", \"ul\": \"ul\", \"el\": \"el\",\n",
    "    \"ay\": \"aj\", \"ey\": \"ej\", \"oy\": \"oj\", \"uy\": \"uj\"\n",
    "}\n",
    "\n",
    "# âœ… Function to Convert Turkish Text â†’ IPA\n",
    "def turkish_to_ipa(word):\n",
    "    \"\"\"\n",
    "    Converts a Turkish word into IPA representation.\n",
    "    \"\"\"\n",
    "    word = word.lower()  # Ensure lowercase\n",
    "    ipa_word = \"\"\n",
    "    \n",
    "    for char in word:\n",
    "        ipa_word += IPA_DICT.get(char, char)  # Replace using dictionary\n",
    "    \n",
    "    return f\"/{ipa_word}/\"  # Return IPA transcription\n",
    "\n",
    "# âœ… Test the function\n",
    "words = [\"merhaba\", \"nasÄ±lsÄ±n\", \"teÅŸekkÃ¼r\", \"gÃ¼zel\", \"TÃ¼rkÃ§e\", \"kedi\", \"ÅŸiÅŸe\", \"uÃ§ak\"]\n",
    "words = \"seni gÃ¶rdÃ¼gÃ¼mde gercekten mutlu oluyorum. inmazsan sor\".split(\" \")\n",
    "ipa_transcriptions = {word: turkish_to_ipa(word) for word in words}\n",
    "\n",
    "# âœ… Display results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(ipa_transcriptions.items(), columns=[\"Turkish\", \"IPA\"])\n",
    "\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merhaba â†’ /mÉ›É¾ha.baËˆ/\n",
      "nasÄ±lsÄ±n â†’ /naËˆ.sÉ¯É«sÉ¯n/\n",
      "teÅŸekkÃ¼r â†’ /tÉ›ÊƒÉ›kkyÉ¾/\n",
      "gÃ¼zel â†’ /É¡yzÉ›É«/\n",
      "doktor â†’ /do.ktoËˆ.É¾/\n",
      "telefon â†’ /tÉ›É«É›foËˆ.n/\n",
      "kaplan â†’ /ka.pÉ«aËˆ.n/\n",
      "yapÄ±yor â†’ /ja.pÉ¯joËˆ.É¾/\n",
      "yapma â†’ /ja.pmaËˆ/\n",
      "evde â†’ /É›vdÉ›/\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# âœ… Turkish letter â†’ IPA phoneme mapping\n",
    "turkish_to_ipa_dict = {\n",
    "    \"a\": \"a\", \"b\": \"b\", \"c\": \"dÊ’\", \"Ã§\": \"tÊƒ\", \"d\": \"d\",\n",
    "    \"e\": \"É›\", \"f\": \"f\", \"g\": \"É¡\", \"ÄŸ\": \"É£\", \"h\": \"h\",\n",
    "    \"Ä±\": \"É¯\", \"i\": \"i\", \"j\": \"Ê’\", \"k\": \"k\", \"l\": \"É«\",\n",
    "    \"m\": \"m\", \"n\": \"n\", \"o\": \"o\", \"Ã¶\": \"Ã¸\", \"p\": \"p\",\n",
    "    \"r\": \"É¾\", \"s\": \"s\", \"ÅŸ\": \"Êƒ\", \"t\": \"t\", \"u\": \"u\",\n",
    "    \"Ã¼\": \"y\", \"v\": \"v\", \"y\": \"j\", \"z\": \"z\"\n",
    "}\n",
    "\n",
    "# âœ… Function to divide words into syllables\n",
    "def syllabify(word):\n",
    "    vowels = \"aÄ±oueiÃ¶Ã¼\"\n",
    "    syllables = []\n",
    "    current_syllable = \"\"\n",
    "\n",
    "    for i, char in enumerate(word):\n",
    "        current_syllable += char\n",
    "        if char in vowels:\n",
    "            if i < len(word) - 1 and word[i + 1] not in vowels:\n",
    "                syllables.append(current_syllable)\n",
    "                current_syllable = \"\"\n",
    "    if current_syllable:\n",
    "        syllables.append(current_syllable)\n",
    "\n",
    "    return syllables\n",
    "\n",
    "# âœ… Function to place primary stress correctly\n",
    "def add_primary_stress(syllables):\n",
    "    if len(syllables) == 1:\n",
    "        return syllables  # One-syllable words donâ€™t need stress\n",
    "    \n",
    "    # Default: Stress the **last vowel-ending syllable**\n",
    "    for i in range(len(syllables) - 1, -1, -1):\n",
    "        if syllables[i][-1] in \"aÄ±oueiÃ¶Ã¼\":\n",
    "            syllables[i] = syllables[i] + \"Ëˆ\"\n",
    "            break\n",
    "\n",
    "    return syllables\n",
    "\n",
    "# âœ… Function to convert Turkish text to IPA\n",
    "def turkish_to_ipa(word):\n",
    "    word = word.lower()\n",
    "    \n",
    "    # Step 1: Convert to IPA\n",
    "    ipa_word = \"\".join([turkish_to_ipa_dict.get(char, char) for char in word])\n",
    "\n",
    "    # Step 2: Syllabify\n",
    "    syllables = syllabify(ipa_word)\n",
    "\n",
    "    # Step 3: Add correct stress placement\n",
    "    stressed_syllables = add_primary_stress(syllables)\n",
    "\n",
    "    return \"/{}/\".format(\".\".join(stressed_syllables))\n",
    "\n",
    "# âœ… Example words\n",
    "words = [\"merhaba\", \"nasÄ±lsÄ±n\", \"teÅŸekkÃ¼r\", \"gÃ¼zel\", \"doktor\", \"telefon\", \"kaplan\", \"yapÄ±yor\", \"yapma\", \"evde\"]\n",
    "\n",
    "# âœ… Convert words to IPA\n",
    "ipa_results = {word: turkish_to_ipa(word) for word in words}\n",
    "\n",
    "# âœ… Display Results\n",
    "for word, ipa in ipa_results.items():\n",
    "    print(f\"{word} â†’ {ipa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'ra', 'ba']\n",
      "['bi', 'Ã§i', 'mi', 'ne']\n",
      "['in', 'sa', 'nÄ±n']\n",
      "['ka', 'ra', 'ca']\n",
      "['al', 'dÄ±']\n",
      "['bir', 'lik']\n",
      "['sev', 'mek']\n",
      "['alt', 'lÄ±k']\n",
      "['tÃ¼rk', 'Ã§e']\n",
      "['kork', 'mak']\n",
      "['al', 'ti', 'ni', ' oy', 'mak']\n"
     ]
    }
   ],
   "source": [
    "def get_syllables(word):\n",
    "    syllables = []\n",
    "\n",
    "    \"\"\"\n",
    "    AÅŸaÄŸÄ±daki satÄ±r gelen kelimenin Ã¼nlÃ¼ harfler 1, Ã¼nsÃ¼zler 0 olacak\n",
    "    ÅŸekilde desenini Ã§Ä±karÄ±r.\n",
    "    Ã–rneÄŸin: arabacÄ± -> 1010101, tÃ¼rkiye -> 010010\n",
    "    \"\"\"\n",
    "\n",
    "    bits = ''.join(['1' if l in 'aeÄ±ioÃ¶uÃ¼' else '0' for l in word])\n",
    "\n",
    "    \"\"\"\n",
    "    AÅŸaÄŸÄ±daki seperators listesi, yakalanacak desenleri ve desen yakalandÄ±ÄŸÄ±nda\n",
    "    kelimenin hangi pozisyondan kesileceÄŸini tanÄ±mlÄ±yor.\n",
    "    TÃ¼rkÃ§ede kelime iÃ§inde iki Ã¼nlÃ¼ arasÄ±ndaki Ã¼nsÃ¼z, kendinden sonraki\n",
    "    Ã¼nlÃ¼yle hece kurar., yani 101 desenini yakaladÄ±ÄŸÄ±mÄ±zda kelimeyi\n",
    "    bulunduÄŸumuz yerden 1 ileri pozisyondan kesmeliyiz. ('101', 1)\n",
    "    Kelime iÃ§inde yan yana gelen iki Ã¼nsÃ¼zden ilki kendinden Ã¶nceki Ã¼nlÃ¼yle,\n",
    "    ikincisi kendinden sonraki Ã¼nlÃ¼yle hece kurar. Bu da demek oluyor ki\n",
    "    1001 desenini yakaladÄ±ÄŸÄ±mÄ±zda kelimeyi bulunduÄŸumuz noktadan 2 ileriden\n",
    "    kesmeliyiz. ('1001', 2),\n",
    "    Kelime iÃ§inde yan yana gelen Ã¼Ã§ Ã¼nsÃ¼z harften ilk ikisi kendinden Ã¶nceki\n",
    "    Ã¼nlÃ¼yle, Ã¼Ã§Ã¼ncÃ¼sÃ¼ kendinden sonraki Ã¼nlÃ¼yle hece kurar. Yani 10001 desenini\n",
    "    gÃ¶rdÃ¼ÄŸÃ¼mÃ¼zde kelimeyi bulunduÄŸumuz yerden 3 ileri pozisyondan kesmemiz\n",
    "    gerek. ('10001', 3)\n",
    "    \"\"\"\n",
    "\n",
    "    seperators = (\n",
    "        ('101', 1),\n",
    "        ('1001', 2),\n",
    "        ('10001', 3)\n",
    "    )\n",
    "\n",
    "    index, cut_start_pos = 0, 0\n",
    "\n",
    "    # index deÄŸerini elimizdeki bitler Ã¼zerinde yÃ¼rÃ¼tmeye baÅŸlÄ±yoruz.\n",
    "    while index < len(bits):\n",
    "\n",
    "        \"\"\"\n",
    "        Elimizdeki her ayÄ±rÄ±cÄ±yÄ± (seperator), bits'in index'inci karakterinden\n",
    "        itibarent tek tek deneyerek yakalamaya Ã§alÄ±ÅŸÄ±yoruz.\n",
    "        \"\"\"\n",
    "\n",
    "        for seperator_pattern, seperator_cut_pos in seperators:\n",
    "            if bits[index:].startswith(seperator_pattern):\n",
    "\n",
    "                \"\"\"\n",
    "                YakaladÄ±ÄŸÄ±mÄ±zda, en son cut_start posizyonundan, bulunduÄŸumuz\n",
    "                pozisyonun serpator_cut_pos kadar ilerisine kadar bÃ¶lÃ¼mÃ¼ alÄ±p\n",
    "                syllables sepetine atÄ±yoruz.\n",
    "                \"\"\"\n",
    "\n",
    "                syllables.append(word[cut_start_pos:index + seperator_cut_pos])\n",
    "\n",
    "                \"\"\"\n",
    "                Index'imiz seperator_cut_pos kadar ilerliyor, ve\n",
    "                cut_start_pos'u index'le aynÄ± yapÄ±yoruz.\n",
    "                \"\"\"\n",
    "\n",
    "                index += seperator_cut_pos\n",
    "                cut_start_pos = index\n",
    "                break\n",
    "\n",
    "        \"\"\"\n",
    "        Index ilerliyor, cut_start_pos'da deÄŸiÅŸiklik yok.\n",
    "        \"\"\"\n",
    "\n",
    "        index += 1\n",
    "\n",
    "    # Son kalan heceyi elle sepete atÄ±yoruz.\n",
    "    syllables.append(word[cut_start_pos:])\n",
    "    return syllables\n",
    "\n",
    "print(get_syllables(u'araba'))\n",
    "print(get_syllables(u'biÃ§imine'))\n",
    "print(get_syllables(u'insanÄ±n'))\n",
    "print(get_syllables(u'karaca'))\n",
    "\n",
    "print(get_syllables(u'aldÄ±'))\n",
    "print(get_syllables(u'birlik'))\n",
    "print(get_syllables(u'sevmek'))\n",
    "\n",
    "print(get_syllables(u'altlÄ±k'))\n",
    "print(get_syllables(u'tÃ¼rkÃ§e'))\n",
    "print(get_syllables(u'korkmak'))\n",
    "print(get_syllables(u'altini oymak'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seni â†’ /sÉ›.Ëˆni/\n",
      "gÃ¶rdÃ¼gÃ¼mde â†’ /É¡Ã¸É¾.dy.É¡ym.ËˆdÉ›/\n",
      "gercekten â†’ /É¡É›É¾.dÊ’É›k.ËˆtÉ›n/\n",
      "mutlu â†’ /mut.ËˆÉ«u/\n",
      "oluyorum. â†’ /o.É«u.jo.ËˆÉ¾um./\n",
      "inmazsan â†’ /in.maz.Ëˆsan/\n",
      "sor â†’ /soÉ¾/\n",
      "sÉ›.Ëˆni É¡Ã¸É¾.dy.É¡ym.ËˆdÉ› É¡É›É¾.dÊ’É›k.ËˆtÉ›n mut.ËˆÉ«u o.É«u.jo.ËˆÉ¾um. in.maz.Ëˆsan soÉ¾ \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# âœ… Turkish letter â†’ IPA phoneme mapping\n",
    "turkish_to_ipa_dict = {\n",
    "    \"a\": \"a\", \"b\": \"b\", \"c\": \"dÊ’\", \"Ã§\": \"tÊƒ\", \"d\": \"d\",\n",
    "    \"e\": \"É›\", \"f\": \"f\", \"g\": \"É¡\", \"ÄŸ\": \"É£\", \"h\": \"h\",\n",
    "    \"Ä±\": \"É¯\", \"i\": \"i\", \"j\": \"Ê’\", \"k\": \"k\", \"l\": \"É«\",\n",
    "    \"m\": \"m\", \"n\": \"n\", \"o\": \"o\", \"Ã¶\": \"Ã¸\", \"p\": \"p\",\n",
    "    \"r\": \"É¾\", \"s\": \"s\", \"ÅŸ\": \"Êƒ\", \"t\": \"t\", \"u\": \"u\",\n",
    "    \"Ã¼\": \"y\", \"v\": \"v\", \"y\": \"j\", \"z\": \"z\"\n",
    "}\n",
    "\n",
    "# âœ… Your syllabification function\n",
    "def get_syllables(word):\n",
    "    vowels = \"aeÄ±ioÃ¶uÃ¼\"\n",
    "    bits = ''.join(['1' if l in vowels else '0' for l in word])\n",
    "\n",
    "    seperators = [\n",
    "        ('101', 1),\n",
    "        ('1001', 2),\n",
    "        ('10001', 3)\n",
    "    ]\n",
    "\n",
    "    index, cut_start_pos = 0, 0\n",
    "    syllables = []\n",
    "\n",
    "    while index < len(bits):\n",
    "        for pattern, cut_pos in seperators:\n",
    "            if bits[index:].startswith(pattern):\n",
    "                syllables.append(word[cut_start_pos:index + cut_pos])\n",
    "                index += cut_pos\n",
    "                cut_start_pos = index\n",
    "                break\n",
    "        index += 1\n",
    "\n",
    "    syllables.append(word[cut_start_pos:])\n",
    "    return syllables\n",
    "\n",
    "# âœ… Function to add primary stress\n",
    "def add_primary_stress(syllables):\n",
    "    if len(syllables) == 1:\n",
    "        return syllables  # One-syllable words donâ€™t need stress\n",
    "    syllables[-1] = \"Ëˆ\" + syllables[-1]  # Default: stress last syllable\n",
    "    return syllables\n",
    "\n",
    "# âœ… Convert Turkish â†’ IPA with syllables\n",
    "def turkish_to_ipa(word):\n",
    "    word = word.lower()\n",
    "    \n",
    "    # Step 1: Get syllables\n",
    "    syllables = get_syllables(word)\n",
    "\n",
    "    # Step 2: Convert each syllable to IPA\n",
    "    ipa_syllables = []\n",
    "    for syl in syllables:\n",
    "        ipa_syll = \"\".join([turkish_to_ipa_dict.get(char, char) for char in syl])\n",
    "        ipa_syllables.append(ipa_syll)\n",
    "\n",
    "    # Step 3: Add stress\n",
    "    stressed_syllables = add_primary_stress(ipa_syllables)\n",
    "\n",
    "    return \"/{}/\".format(\".\".join(stressed_syllables))\n",
    "\n",
    "# âœ… Example words\n",
    "words = [\"deÄŸil\",\"merhaba\", \"nasÄ±lsÄ±n\", \"teÅŸekkÃ¼r\", \"gÃ¼zel\", \"doktor\", \"telefon\", \"kaplan\", \"yapÄ±yor\", \"yapma\", \"evde\"]\n",
    "words = \"seni gÃ¶rdÃ¼gÃ¼mde gercekten mutlu oluyorum. inmazsan sor\".split(\" \")\n",
    "\n",
    "# âœ… Convert words to IPA\n",
    "ipa_results = {word: turkish_to_ipa(word) for word in words}\n",
    "loanwords = {\n",
    "    \"telefon\", \"televizyon\", \"mÃ¼zik\", \"kÃ¼ltÃ¼r\", \"problem\",\n",
    "    \"futbol\", \"doktor\", \"radyo\", \"otel\", \"tren\", \"klasik\", \"teknoloji\"\n",
    "}\n",
    "\n",
    "# âœ… Process IPA Results with Fixes\n",
    "corrected_ipa_results = {}\n",
    "for word, ipa in ipa_results.items():\n",
    "    if word in loanwords:\n",
    "        # Ensure first occurrence of 'Ê' â†’ 'y' and 'É›' â†’ 'e' are replaced\n",
    "        if \"Ê\" in ipa:\n",
    "            ipa = ipa.replace(\"Ê\",\"y\")\n",
    "        if \"É›\" in ipa:\n",
    "            ipa = ipa.replace(\"É›\",\"e\")\n",
    "    corrected_ipa_results[word] = ipa\n",
    "\n",
    "# âœ… Display Results\n",
    "new_sen=\"\"\n",
    "for word, ipa in corrected_ipa_results.items():\n",
    "    new_sen += ipa + \" \"\n",
    "    \n",
    "    print(f\"{word} â†’ {ipa}\")\n",
    "print(new_sen.replace(\"/\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wollen wir das Ganze einfach mal ausfÃ¼hren â†’ fÉ”.llÉ›.n fÉª.r da.s ga.ntÍ¡sÉ›. É›Éª.nfa.x ma.l a.ÊŠsfÊ.hrÉ›.n\n",
      "Das ist ein Test â†’ da.s Éª.Êƒt É›Éª.n tÉ›.Êƒt\n",
      "KÃ¶nnen wir den Text ins IPA umwandeln â†’ kÅ“.nnÉ›.n fÉª.r dÉ›.n tÉ›.xt Éª.ns Éª.pa. ÊŠmfa.ndÉ›.ln\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def text_to_german_ipa(text):\n",
    "    # German vowel and consonant mappings\n",
    "    vowel_map = {\n",
    "        'a': 'a', 'e': 'É›', 'i': 'Éª', 'o': 'É”', 'u': 'ÊŠ',\n",
    "        'Ã¤': 'É›', 'Ã¶': 'Å“', 'Ã¼': 'Ê', 'ei': 'aÉªÌ¯', 'ie': 'iË',\n",
    "        'au': 'aÊŠÌ¯', 'eu': 'É”ÉªÌ¯', 'Ã¤u': 'É”ÉªÌ¯'\n",
    "    }\n",
    "\n",
    "    consonant_map = {\n",
    "        'w': 'v', 'j': 'j', 'v': 'f', 'z': 'tÍ¡s',\n",
    "        'sch': 'Êƒ', 'ch': 'x', 'tsch': 'tÍ¡Êƒ', 'pf': 'pf',\n",
    "        's$': 's', '^s': 'z', 'sp': 'Êƒp', 'st': 'Êƒt'\n",
    "    }\n",
    "\n",
    "    # Apply vowel transformations\n",
    "    for seq, ipa in vowel_map.items():\n",
    "        text = re.sub(seq, ipa, text)\n",
    "\n",
    "    # Apply consonant transformations\n",
    "    for seq, ipa in consonant_map.items():\n",
    "        text = re.sub(seq, ipa, text)\n",
    "\n",
    "    # Handle final consonants with devoicing\n",
    "    text = re.sub(r'b$', 'p', text)\n",
    "    text = re.sub(r'd$', 't', text)\n",
    "    text = re.sub(r'g$', 'k', text)\n",
    "\n",
    "    # Insert syllable boundaries (simple heuristic)\n",
    "    text = re.sub(r'([aeiouÃ¤Ã¶Ã¼ÉªÉ›ÊÅ“É”É])([^aeiouÃ¤Ã¶Ã¼ÉªÉ›ÊÅ“É”É])', r'\\1.\\2', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Test the function\n",
    "sentences = [\n",
    "    \"Wollen wir das Ganze einfach mal ausfÃ¼hren\",\n",
    "    \"Das ist ein Test\",\n",
    "    \"KÃ¶nnen wir den Text ins IPA umwandeln\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    ipa = text_to_german_ipa(sentence.lower())\n",
    "    print(f\"{sentence} â†’ {ipa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wollen â†’ ËˆWÉ”.llÉ›.n\n",
      "wir â†’ ËˆvÉª.Ê\n",
      "das â†’ Ëˆda.z\n",
      "Ganze â†’ ËˆGa.ntÍ¡sÉ›\n",
      "einfach â†’ ËˆÉ›Éª.nfa.kh\n",
      "mal â†’ Ëˆma.l\n",
      "ausfÃ¼hren â†’ ËˆaÊŠ.zfÊ.hÊÉ›.n\n",
      "Das â†’ ËˆDa.z\n",
      "ist â†’ ËˆÉª.zt\n",
      "ein â†’ ËˆÉ›Éª.n\n",
      "Test â†’ ËˆTÉ›.zt\n",
      "KÃ¶nnen â†’ ËˆKÅ“.nnÉ›.n\n",
      "wir â†’ ËˆvÉª.Ê\n",
      "den â†’ ËˆdÉ›.n\n",
      "Text â†’ ËˆTÉ›.kst\n",
      "ins â†’ ËˆÉª.nz\n",
      "IPA â†’ ËˆI.PA\n",
      "umwandeln â†’ ËˆÊŠ.mva.ndÉ›.ln\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_german_syllables(word):\n",
    "    vowels = \"aeiouÃ¤Ã¶Ã¼yAEIOUÃ„Ã–Ãœ\"\n",
    "    syllables = []\n",
    "    current_syllable = \"\"\n",
    "\n",
    "    for i, char in enumerate(word):\n",
    "        current_syllable += char\n",
    "        if char in vowels:\n",
    "            if i < len(word) - 1 and word[i+1] not in vowels:\n",
    "                syllables.append(current_syllable)\n",
    "                current_syllable = \"\"\n",
    "    if current_syllable:\n",
    "        syllables.append(current_syllable)\n",
    "\n",
    "    return syllables\n",
    "\n",
    "def german_to_ipa(word):\n",
    "    ipa_mapping = {\n",
    "        \"a\": \"a\", \"b\": \"b\", \"c\": \"k\", \"d\": \"d\", \"e\": \"É›\", \"f\": \"f\", \"g\": \"g\", \"h\": \"h\", \"i\": \"Éª\", \"j\": \"j\", \"k\": \"k\", \"l\": \"l\", \"m\": \"m\", \"n\": \"n\", \"o\": \"É”\", \"p\": \"p\", \"q\": \"k\", \"r\": \"Ê\", \"s\": \"z\", \"ÃŸ\": \"s\", \"t\": \"t\", \"u\": \"ÊŠ\", \"v\": \"f\", \"w\": \"v\", \"x\": \"ks\", \"y\": \"Ê\", \"z\": \"tÍ¡s\",\n",
    "        \"Ã¤\": \"É›\", \"Ã¶\": \"Å“\", \"Ã¼\": \"Ê\"\n",
    "    }\n",
    "    syllables = get_german_syllables(word)\n",
    "    ipa_syllables = []\n",
    "\n",
    "    for syllable in syllables:\n",
    "        ipa_syllable = \"\"\n",
    "        for char in syllable:\n",
    "            ipa_syllable += ipa_mapping.get(char, char)\n",
    "        ipa_syllables.append(ipa_syllable)\n",
    "\n",
    "    # Add primary stress to the first syllable for simplicity\n",
    "    if ipa_syllables:\n",
    "        ipa_syllables[0] = \"Ëˆ\" + ipa_syllables[0]\n",
    "\n",
    "    return \".\".join(ipa_syllables)\n",
    "\n",
    "# Test the function\n",
    "german_sentences = [\n",
    "    \"Wollen\", \"wir\", \"das\", \"Ganze\", \"einfach\", \"mal\", \"ausfÃ¼hren\",\n",
    "    \"Das\", \"ist\", \"ein\", \"Test\",\n",
    "    \"KÃ¶nnen\", \"wir\", \"den\", \"Text\", \"ins\", \"IPA\", \"umwandeln\"\n",
    "]\n",
    "\n",
    "for word in german_sentences:\n",
    "    ipa = german_to_ipa(word)\n",
    "    print(f\"{word} â†’ {ipa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: Wollen wir das Ganze einfach mal ausfÃ¼hren\n",
      "IPA: 'v É” l É™ nv iË' É¾d a.'sÉ¡ a.'n ts É™ aÉª.'n f a.'xm É‘Ë l aÊŠ.'s f yË r É™ n\n"
     ]
    }
   ],
   "source": [
    "from phonemizer import phonemize\n",
    "from phonemizer.separator import Separator\n",
    "import re\n",
    "\n",
    "\n",
    "def german_to_ipa_with_syllables(text):\n",
    "    \"\"\"\n",
    "    Converts a German sentence to IPA with syllable boundaries and stress markers.\n",
    "\n",
    "    Args:\n",
    "        text (str): The German sentence to convert.\n",
    "\n",
    "    Returns:\n",
    "        str: The IPA transcription with syllable boundaries and stress markers.\n",
    "    \"\"\"\n",
    "    # Step 1: Get initial IPA transcription\n",
    "    separator = Separator(phone=' ', word=None)\n",
    "    ipa_text = phonemize(\n",
    "        text,\n",
    "        language='de',\n",
    "        backend='espeak',\n",
    "        separator=separator,\n",
    "        strip=True,\n",
    "        njobs=1\n",
    "    )\n",
    "\n",
    "    # Step 2: Add syllable boundaries (simple heuristic)\n",
    "    ipa_text = re.sub(r'([aeiouyÃ¤Ã¶Ã¼ÉªÉ›Ã¦ÊŠÉ]) ', r'\\1.', ipa_text)  # Add '.' after vowels\n",
    "\n",
    "    # Step 3: Add primary stress to first vowel in each word (simplistic rule)\n",
    "    ipa_text = re.sub(r'\\b([^.]*?[aeiouyÃ¤Ã¶Ã¼ÉªÉ›Ã¦ÊŠÉ])', r\"'\\1\", ipa_text)\n",
    "\n",
    "    # Step 4: Handle common diphthongs\n",
    "    ipa_text = ipa_text.replace('ai', 'aÉªÌ¯').replace('ei', 'aÉªÌ¯').replace('au', 'aÊŠÌ¯').replace('eu', 'É”ÊÌ¯').replace('Ã¤u', 'É”ÊÌ¯')\n",
    "\n",
    "    return ipa_text\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "german_sentence = \"Wollen wir das Ganze einfach mal ausfÃ¼hren\"\n",
    "ipa_transcription = german_to_ipa_with_syllables(german_sentence)\n",
    "print(f\"German: {german_sentence}\")\n",
    "print(f\"IPA: {ipa_transcription}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wollen wir das Ganze einfach mal ausfÃ¼hren â†’ Ëˆwo.lle.n Ëˆwi.Ê Ëˆda.s Ëˆga.ntse Ëˆa.Éª.Ì¯nfa.x Ëˆma.l Ëˆa.ÊŠÌ¯sfÊ.hÊe.n\n",
      "Das ist ein Test â†’ Ëˆda.s Ëˆi.Êƒt Ëˆa.Éª.Ì¯n Ëˆte.Êƒt\n",
      "KÃ¶nnen wir den Text ins IPA umwandeln â†’ ËˆkÅ“.nne.n Ëˆwi.Ê Ëˆde.n Ëˆte.xt Ëˆi.ns Ëˆi.pa Ëˆu.mwa.nde.ln\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def german_to_ipa(text):\n",
    "    ipa_mapping = {\n",
    "        \"sch\": \"Êƒ\", \"ch\": \"x\", \"z\": \"ts\", \"j\": \"j\", \"r\": \"Ê\", \"ng\": \"Å‹\",\n",
    "        \"au\": \"aÊŠÌ¯\", \"ei\": \"aÉªÌ¯\", \"eu\": \"É”ÊÌ¯\", \"Ã¤u\": \"É”ÊÌ¯\", \"sp\": \"Êƒp\", \"st\": \"Êƒt\",\n",
    "        \"Ã¤\": \"É›\", \"Ã¶\": \"Å“\", \"Ã¼\": \"Ê\", \"ÃŸ\": \"s\", \"ph\": \"f\", \"qu\": \"kv\"\n",
    "    }\n",
    "\n",
    "    words = text.lower().split()\n",
    "    ipa_words = []\n",
    "\n",
    "    for word in words:\n",
    "        ipa_word = word\n",
    "        for key, val in ipa_mapping.items():\n",
    "            ipa_word = ipa_word.replace(key, val)\n",
    "\n",
    "        # Insert syllable boundaries and primary stress for the first syllable\n",
    "        ipa_word = re.sub(r\"([aeiouÃ¤Ã¶Ã¼ÉªÉ›Å“Ê])\", r\"\\1.\", ipa_word)  # syllables after vowels\n",
    "        ipa_word = re.sub(r\"\\.$\", \"\", ipa_word)  # remove trailing syllable\n",
    "        ipa_word = \"Ëˆ\" + ipa_word  # add primary stress\n",
    "\n",
    "        ipa_words.append(ipa_word)\n",
    "\n",
    "    return \" \".join(ipa_words)\n",
    "\n",
    "# Test the function\n",
    "sentences = [\n",
    "    \"Wollen wir das Ganze einfach mal ausfÃ¼hren\",\n",
    "    \"Das ist ein Test\",\n",
    "    \"KÃ¶nnen wir den Text ins IPA umwandeln\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    ipa = german_to_ipa(sentence.lower())\n",
    "    print(f\"{sentence} â†’ {ipa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… IPA conversion completed. Saved to audio_dataset/metadata_ipa.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def convert_metadata_to_ipa(input_file='audio_dataset/metadata.csv', output_file='audio_dataset/metadata_ipa.csv'):\n",
    "    \"\"\"Converts the second column of metadata.csv to IPA and saves it\"\"\"\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        reader = csv.reader(infile, delimiter='|')\n",
    "        writer = csv.writer(outfile, delimiter='|')\n",
    "\n",
    "        for row in reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "\n",
    "            original_text = row[1]\n",
    "            ipa_text = german_to_ipa(original_text)\n",
    "\n",
    "            new_row = [row[0], f\"/{ipa_text}/\", row[2]]\n",
    "            writer.writerow(new_row)\n",
    "\n",
    "    print(f\"âœ… IPA conversion completed. Saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Run the conversion\n",
    "convert_metadata_to_ipa()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
